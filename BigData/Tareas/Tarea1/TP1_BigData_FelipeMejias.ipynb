{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1-BigData-FelipeMejias.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmejias/CienciasDeLosDatosTEC/blob/master/BigData/Tareas/Tarea1/TP1_BigData_FelipeMejias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoVzbpenBYwm",
        "colab_type": "text"
      },
      "source": [
        "# Big Data\n",
        "# Trabajo práctico 1\n",
        "\n",
        "- Professor: Luis Chavarría.\n",
        "\n",
        "- Student:  \n",
        "    - Felipe Alberto Mejías Loría, Instituto Tecnológico de Costa Rica. \n",
        "\n",
        "- November 28th, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16-eehY1yTlt",
        "colab_type": "text"
      },
      "source": [
        "## **1-) Instalación de PySpark y Optimus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvwXXdbU-vR",
        "colab_type": "code",
        "outputId": "79b4c46e-68fd-4a5e-f9ec-ab25959adc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install necessary libraries\n",
        "!pip3 install pyspark\n",
        "!pip install -q findspark\n",
        "!pip install optimuspyspark\n",
        "\n",
        "# Needed to install Spark in Google Colab\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
            "Requirement already satisfied: optimuspyspark in /usr/local/lib/python3.6/dist-packages (2.2.29)\n",
            "Requirement already satisfied: findspark==1.3.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.3.0)\n",
            "Requirement already satisfied: glom==19.10.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (19.10.0)\n",
            "Requirement already satisfied: simplejson==3.16.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (3.16.0)\n",
            "Requirement already satisfied: pyarrow==0.13.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.13.0)\n",
            "Requirement already satisfied: psutil==5.6.3 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (5.6.3)\n",
            "Requirement already satisfied: h2o-pysparkling-2.4==2.4.13 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.4.13)\n",
            "Requirement already satisfied: multipledispatch==0.6.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.6.0)\n",
            "Requirement already satisfied: numpy==1.17.2 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.17.2)\n",
            "Requirement already satisfied: flask==1.0.2 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.0.2)\n",
            "Requirement already satisfied: backoff==1.8.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.8.0)\n",
            "Requirement already satisfied: tqdm==4.28.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (4.28.1)\n",
            "Requirement already satisfied: pymongo==3.9.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (3.9.0)\n",
            "Requirement already satisfied: fastnumbers==2.2.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.2.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.24.2)\n",
            "Requirement already satisfied: cryptography==2.7 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.7)\n",
            "Requirement already satisfied: requests==2.20.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.20.0)\n",
            "Requirement already satisfied: ratelimit==2.2.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.2.1)\n",
            "Requirement already satisfied: deprecated==1.2.5 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.2.5)\n",
            "Requirement already satisfied: setuptools==41.6.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (41.6.0)\n",
            "Requirement already satisfied: ordered-set==3.1.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (3.1.1)\n",
            "Requirement already satisfied: singleton-decorator==1.0.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.0.0)\n",
            "Requirement already satisfied: matplotlib==3.0.3 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (3.0.3)\n",
            "Requirement already satisfied: pypika==0.32.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.32.0)\n",
            "Requirement already satisfied: ipython==7.5.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (7.5.0)\n",
            "Requirement already satisfied: packaging==19.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (19.1)\n",
            "Requirement already satisfied: humanize==0.5.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.5.1)\n",
            "Requirement already satisfied: pyspark==2.4.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.4.1)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.4.2)\n",
            "Requirement already satisfied: kombu==4.6.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (4.6.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.9.0)\n",
            "Requirement already satisfied: deepdiff==4.0.6 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (4.0.6)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.2.4)\n",
            "Requirement already satisfied: statsmodels==0.10.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (0.10.1)\n",
            "Requirement already satisfied: Jinja2==2.10.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (2.10.1)\n",
            "Requirement already satisfied: imgkit==1.0.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.0.1)\n",
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.6/dist-packages (from optimuspyspark) (1.13.1)\n",
            "Requirement already satisfied: boltons>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from glom==19.10.0->optimuspyspark) (19.3.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from glom==19.10.0->optimuspyspark) (19.3.0)\n",
            "Requirement already satisfied: face in /usr/local/lib/python3.6/dist-packages (from glom==19.10.0->optimuspyspark) (19.1.2)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.13.0->optimuspyspark) (1.12.0)\n",
            "Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.6/dist-packages (from h2o-pysparkling-2.4==2.4.13->optimuspyspark) (0.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o-pysparkling-2.4==2.4.13->optimuspyspark) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o-pysparkling-2.4==2.4.13->optimuspyspark) (0.8.5)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->optimuspyspark) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->optimuspyspark) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->optimuspyspark) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->optimuspyspark) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->optimuspyspark) (2.6.1)\n",
            "Requirement already satisfied: asn1crypto>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from cryptography==2.7->optimuspyspark) (1.2.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography==2.7->optimuspyspark) (1.13.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.0->optimuspyspark) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.0->optimuspyspark) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.0->optimuspyspark) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.0->optimuspyspark) (2.7)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated==1.2.5->optimuspyspark) (1.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->optimuspyspark) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->optimuspyspark) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->optimuspyspark) (2.4.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (4.7.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (0.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (2.0.10)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (0.15.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (4.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->optimuspyspark) (4.4.1)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark==2.4.1->optimuspyspark) (0.10.7)\n",
            "Requirement already satisfied: amqp<3.0,>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from kombu==4.6.1->optimuspyspark) (2.5.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->optimuspyspark) (1.3.2)\n",
            "Requirement already satisfied: jsonpickle>=1.0 in /usr/local/lib/python3.6/dist-packages (from deepdiff==4.0.6->optimuspyspark) (1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->optimuspyspark) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->optimuspyspark) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->optimuspyspark) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->optimuspyspark) (1.0.8)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.10.1->optimuspyspark) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2==2.10.1->optimuspyspark) (1.1.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->optimuspyspark) (0.33.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography==2.7->optimuspyspark) (2.19)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.5.0->optimuspyspark) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.5.0->optimuspyspark) (0.1.7)\n",
            "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.5.0->optimuspyspark) (0.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython==7.5.0->optimuspyspark) (0.2.0)\n",
            "Requirement already satisfied: vine<5.0.0a1,>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from amqp<3.0,>=2.5.0->kombu==4.6.1->optimuspyspark) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->optimuspyspark) (3.1.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->optimuspyspark) (3.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPYcvcFbykrU",
        "colab_type": "text"
      },
      "source": [
        "# **2-) Actualizar variables de ambiente necesarias para correr Spark en Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6fZTu6QCCcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set necessary environmental variables to use Apache Spark in Google Colab\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etOFvKZQy3vz",
        "colab_type": "text"
      },
      "source": [
        "# **3-) Importar bibliotecas necesarias para la ejecución de la TP1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr7X3A0ezHGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Necessary Imports for the execution of the TP1\n",
        "import pandas as pd\n",
        "import findspark\n",
        "from datetime import datetime\n",
        "from pyspark.sql import SparkSession, Row, dataframe\n",
        "from pyspark.sql.functions import col, date_format, udf, array\n",
        "from pyspark.sql.types import DateType\n",
        "from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n",
        "from optimus import Optimus\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "# Set SPARK_HOME. Needed to initialize Apache Spark.\n",
        "findspark.init(\"spark-2.4.4-bin-hadoop2.7\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xi2rFcAzRP3",
        "colab_type": "text"
      },
      "source": [
        "# **4-) Funciones utilitarias para la construcción de DataFrames y de obtención de valores específicos de los DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsVJnOhA0PXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSV Files Path\n",
        "STUDENTS_CSV_PATH = \"https://raw.githubusercontent.com/fmejias/CienciasDeLosDatosTEC/master/BigData/Tareas/Tarea1/estudiante.csv\"\n",
        "COURSE_CSV_PATH = \"https://raw.githubusercontent.com/fmejias/CienciasDeLosDatosTEC/master/BigData/Tareas/Tarea1/curso.csv\"\n",
        "GRADES_CSV_PATH = \"https://raw.githubusercontent.com/fmejias/CienciasDeLosDatosTEC/master/BigData/Tareas/Tarea1/nota.csv\"\n",
        "\n",
        "def create_spark_session():\n",
        "  \"\"\"\n",
        "  This function builds a Spark Session\n",
        "  return the main entry of a Spark DataFrame\n",
        "  \"\"\"\n",
        "  spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Basic JDBC pipeline\") \\\n",
        "    .getOrCreate()\n",
        "  return spark\n",
        "\n",
        "def create_spark_data_frame_from_csv_file(csv_file):\n",
        "  \"\"\"\n",
        "  This function loads a Web CSV file into a Spark DataFrame using Optimus\n",
        "  csv_file: Web CSV File\n",
        "  return the Spark DataFrame from the CSV\n",
        "  \"\"\"\n",
        "  try:\n",
        "    op = Optimus()\n",
        "    spark_data_frame = op.load.csv(csv_file)\n",
        "    spark_data_frame.show(spark_data_frame.count(), False)\n",
        "    return spark_data_frame\n",
        "  except HTTPError as csv_ex:\n",
        "    raise RuntimeError(\"El URL del archivo CSV especificado no existe: {}\".format(\n",
        "                csv_file)) from csv_ex\n",
        "\n",
        "def show_complete_spark_data_frame(spark_data_frame):\n",
        "  \"\"\"\n",
        "  This function shows the complete spark_data_frame\n",
        "  \"\"\"\n",
        "  spark_data_frame.show(spark_data_frame.count(), False)\n",
        "\n",
        "def get_column_values_to_list(data_frame, column_name):\n",
        "  \"\"\"\n",
        "  This function returns the values of a column into a list\n",
        "  data_frame: Spark DataFrame\n",
        "  column_name: Column Name to get the values from\n",
        "  \"\"\"\n",
        "  return data_frame.select(column_name).rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "def join_spark_data_frames(data_frame_1, data_frame_2,\n",
        "                           using_column_data_frame_1,\n",
        "                           using_column_data_frame_2):\n",
        "  \"\"\"\n",
        "  This function joint two Spark Data Frames\n",
        "  data_frame_1: Spark DataFrame 1\n",
        "  data_frame_2: Spark DataFrame 2\n",
        "  using_column_data_frame_1: Column from DataFrame 1 to compare\n",
        "  using_column_data_frame_2: Column from DataFrame 2 to compare\n",
        "  return the Spark DataFrame from the JOIN\n",
        "  \"\"\"\n",
        "  using_columns_statement = using_column_data_frame_1 == using_column_data_frame_2\n",
        "  joint_data_frame = data_frame_1.join(data_frame_2, using_columns_statement)\n",
        "\n",
        "  # To remove duplicated columns\n",
        "  joint_data_frame = joint_data_frame.drop(using_column_data_frame_1)\n",
        "\n",
        "  show_complete_spark_data_frame(joint_data_frame)\n",
        "  return joint_data_frame\n",
        "\n",
        "def create_data_frame_with_grades_by_student(joint_data_frame, student_carnet):\n",
        "  \"\"\"\n",
        "  This function builds a DataFrame of grades by specified student\n",
        "  joint_data_frame: Joint DataFrame with Grades, Students and Courses\n",
        "  student_carnet: Student Carnet\n",
        "  return the Spark DataFrame with the grades of the specified student\n",
        "  \"\"\"\n",
        "  filter_statement = joint_data_frame.Carnet == student_carnet\n",
        "  grades_by_student_data_frame = joint_data_frame.filter(filter_statement)\n",
        "  show_complete_spark_data_frame(grades_by_student_data_frame)\n",
        "  return grades_by_student_data_frame\n",
        "\n",
        "def add_column_grades_times_credits_by_student(grades_by_student_data_frame):\n",
        "  \"\"\"\n",
        "  This function add another column to the Filter DataFrame that contains\n",
        "  the grades of the student\n",
        "  grades_by_student_data_frame: Filter DataFrame with the grades of the student\n",
        "  return the Spark DataFrame with the grades of the specified student and a \n",
        "         additional column with the calculation of grade times credits\n",
        "  \"\"\"\n",
        "  grades_times_credits_op = grades_by_student_data_frame['Creditos']*grades_by_student_data_frame['Nota']\n",
        "  grades_by_student_df = grades_by_student_data_frame.withColumn('CreditosxNotas',\n",
        "                                                                 grades_times_credits_op)\n",
        "  show_complete_spark_data_frame(grades_by_student_df)\n",
        "  return grades_by_student_df\n",
        "\n",
        "def create_weighted_average_row(student_data_frame):\n",
        "  \"\"\"\n",
        "  This function creates a weighted average row for an specific student\n",
        "  student_data_frame: DataFrame with the grades and grades times credits of a student\n",
        "  return the Spark Row with the weighted average of a student\n",
        "  \"\"\"\n",
        "  sum_of_credits = sum(get_column_values_to_list(student_data_frame,\n",
        "                                                 'Creditos'))\n",
        "  list_of_weighted_averages = get_column_values_to_list(student_data_frame,\n",
        "                                                        'CreditosxNotas')\n",
        "  weighted_average = sum(list_of_weighted_averages)/sum_of_credits\n",
        "  student_name = set(get_column_values_to_list(student_data_frame,\n",
        "                                               'NombreCompleto')).pop()\n",
        "  career_name = set(get_column_values_to_list(student_data_frame,\n",
        "                                              'Carrera')).pop()\n",
        "  weighted_average_row = Row(\"NombreCompleto\", \"Carrera\", \"PromedioPonderado\")\n",
        "  return weighted_average_row(student_name, career_name, weighted_average)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qz_1dBJJgFd",
        "colab_type": "text"
      },
      "source": [
        "# **5-) Funciones principales del programa y función main() para ejecutar el programa que obtiene los dos mejores estudiantes por carrera**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSp6jIOgBXzs",
        "colab_type": "code",
        "outputId": "dc65b07e-7846-4b45-ecb8-281166613c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_data_frame_of_weighted_averages(joint_data_frame):\n",
        "  \"\"\"\n",
        "  This function creates the data frame of the students weighted averages\n",
        "  joint_data_frame: DataFrame with the notes, courses and students info\n",
        "  return the weighted averages Spark DataFrame\n",
        "  \"\"\"\n",
        "\n",
        "  # Extract all carnets from joint data frame\n",
        "  student_carnet_set = set(get_column_values_to_list(joint_data_frame,\n",
        "                                                     'Carnet'))\n",
        "\n",
        "  # Iterate through each of the students and create a data frame with the \n",
        "  # results of the student\n",
        "  students_rows = []\n",
        "  for student_carnet in student_carnet_set:\n",
        "    print(\"Ahora se muestra el DataFrame con las notas del estudiante con carnet:\",\n",
        "          student_carnet,\"\\n\")\n",
        "    student_data_frame = create_data_frame_with_grades_by_student(joint_data_frame,\n",
        "                                                                  student_carnet)\n",
        "    \n",
        "    print(\"Ahora se muestra el DataFrame con las notas y los poderados por credito\",\n",
        "          \"del estudiante con carnet:\", student_carnet,\"\\n\")\n",
        "    student_data_frame = add_column_grades_times_credits_by_student(student_data_frame)\n",
        "\n",
        "    # Create the weighted average row of the student\n",
        "    student_weighted_average_row = create_weighted_average_row(student_data_frame)\n",
        "    students_rows.append(student_weighted_average_row)\n",
        "  \n",
        "  # Create Weighted Averages DataFrame\n",
        "  spark = create_spark_session()\n",
        "  weigthed_averages_data_frame = spark.createDataFrame(students_rows,\n",
        "                                                       ['NombreCompleto',\n",
        "                                                        'Carrera',\n",
        "                                                        'PromedioPonderado'])\n",
        "\n",
        "  # Show weighted_averages data frame\n",
        "  print(\"Los promedios ponderados de los estudiantes son los siguientes:\", \"\\n\")\n",
        "  show_complete_spark_data_frame(weigthed_averages_data_frame)\n",
        "  return weigthed_averages_data_frame\n",
        "  \n",
        "\n",
        "def create_joint_spark_data_frames(student_data_frame, course_data_frame,\n",
        "                                   grades_data_frame):\n",
        "  \"\"\"\n",
        "  This function creates the data frame of the joint of the three datasets\n",
        "  student_data_frame: DataFrame with the students info\n",
        "  course_data_frame: DataFrame with the courses info\n",
        "  grades_data_frame: DataFrame with the grades info\n",
        "  return the joint Spark DataFrame\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"\\nLa unión de los datos de entrada de los cursos y las notas da el\",\n",
        "        \"siguiente DataFrame: \\n\")\n",
        "  joint_grades_and_course_df = join_spark_data_frames(course_data_frame,\n",
        "                                                      grades_data_frame,\n",
        "                                                      course_data_frame.CodigoCurso,\n",
        "                                                      grades_data_frame.CodigoCurso)\n",
        "\n",
        "  print(\"\\nLa unión de los datos de entrada de los cursos y las notas, junto\",\n",
        "        \"con los datos de los estudiantes da el siguiente DataFrame: \\n\")\n",
        "  joint_students_grades_and_course_df = join_spark_data_frames(student_data_frame,\n",
        "                                                               joint_grades_and_course_df,\n",
        "                                                               student_data_frame.Carnet,\n",
        "                                                               joint_grades_and_course_df.Carnet).drop(joint_grades_and_course_df.Carrera)\n",
        "  return joint_students_grades_and_course_df\n",
        "\n",
        "def select_best_n_students_per_career(weighted_averages_data_frame, n=2):\n",
        "  \"\"\"\n",
        "  This function selects the best N students per career\n",
        "  weighted_averages_data_frame: DataFrame with the weighted averages info\n",
        "  n: number of students to select\n",
        "  \"\"\"\n",
        "  # Extract all careers from weighted averages data frame\n",
        "  careers_set = set(get_column_values_to_list(weighted_averages_data_frame,\n",
        "                                              'Carrera'))\n",
        "  for career in careers_set:\n",
        "    filter_statement = weighted_averages_data_frame.Carrera == career\n",
        "    filter_weighted_averages_df = weighted_averages_data_frame.filter(filter_statement)\n",
        "\n",
        "    # Order by descending notes\n",
        "    filter_weighted_averages_df = filter_weighted_averages_df.orderBy(filter_weighted_averages_df.PromedioPonderado.desc())\n",
        "    \n",
        "    # Select first N columns\n",
        "    select_best_n_students_data_frame = filter_weighted_averages_df.limit(n)\n",
        "\n",
        "    # Show best N students\n",
        "    print(\"Los mejores \", n, \"estudiantes de la carrera: \", career, \"\\n\")\n",
        "    show_complete_spark_data_frame(select_best_n_students_data_frame)\n",
        "\n",
        "\n",
        "def main():\n",
        "  \"\"\"\n",
        "  This function calculates the best weighted averages of N students per career\n",
        "  \"\"\"\n",
        "\n",
        "  # Create Spark Data Frames from CSV\n",
        "  print(\"\\nLos datos de entrada de los estudiantes son los siguientes: \\n\")\n",
        "  student_data_frame = create_spark_data_frame_from_csv_file(STUDENTS_CSV_PATH)\n",
        "\n",
        "  print(\"\\nLos datos de entrada de los cursos son los siguientes: \\n\")\n",
        "  course_data_frame  = create_spark_data_frame_from_csv_file(COURSE_CSV_PATH)\n",
        "\n",
        "  print(\"\\nLos datos de entrada de las notas son los siguientes: \\n\")\n",
        "  grades_data_frame  = create_spark_data_frame_from_csv_file(GRADES_CSV_PATH)\n",
        "\n",
        "  # Joint Spark Data Frames\n",
        "  joint_data_frame   = create_joint_spark_data_frames(student_data_frame,\n",
        "                                                      course_data_frame,\n",
        "                                                      grades_data_frame)\n",
        "  \n",
        "  # Create Weighted Averages Spark Data Frame\n",
        "  weighted_averages_data_frame = create_data_frame_of_weighted_averages(joint_data_frame)\n",
        "\n",
        "  # Select best two students per career\n",
        "  select_best_n_students_per_career(weighted_averages_data_frame, n=2)\n",
        "\n",
        "# Execute main program\n",
        "main()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Los datos de entrada de los estudiantes son los siguientes: \n",
            "\n",
            "+------+----------------+--------------------------+\n",
            "|Carnet|NombreCompleto  |Carrera                   |\n",
            "+------+----------------+--------------------------+\n",
            "|2000  |Felipe Mejias   |Ingenieria en Computadores|\n",
            "|2001  |Daniel Canessa  |Ingenieria en Computadores|\n",
            "|2002  |Daniel Chacon   |Ingenieria en Computadores|\n",
            "|2003  |Edgar Campos    |Ingenieria Electronica    |\n",
            "|2004  |Roberto Bolanos |Ingenieria Electronica    |\n",
            "|2005  |Esteban Ferarios|Ingenieria Electronica    |\n",
            "+------+----------------+--------------------------+\n",
            "\n",
            "\n",
            "Los datos de entrada de los cursos son los siguientes: \n",
            "\n",
            "+-----------+--------+--------------------------+\n",
            "|CodigoCurso|Creditos|Carrera                   |\n",
            "+-----------+--------+--------------------------+\n",
            "|1          |4       |Ingenieria en Computadores|\n",
            "|2          |3       |Ingenieria Electronica    |\n",
            "|3          |3       |Ingenieria Electronica    |\n",
            "|4          |2       |Ingenieria Electronica    |\n",
            "|5          |4       |Ingenieria en Computadores|\n",
            "|6          |3       |Ingenieria en Computadores|\n",
            "+-----------+--------+--------------------------+\n",
            "\n",
            "\n",
            "Los datos de entrada de las notas son los siguientes: \n",
            "\n",
            "+------+-----------+----+\n",
            "|Carnet|CodigoCurso|Nota|\n",
            "+------+-----------+----+\n",
            "|2000  |1          |95  |\n",
            "|2000  |5          |90  |\n",
            "|2000  |6          |80  |\n",
            "|2001  |1          |90  |\n",
            "|2001  |5          |70  |\n",
            "|2001  |6          |75  |\n",
            "|2002  |1          |85  |\n",
            "|2002  |5          |95  |\n",
            "|2002  |6          |75  |\n",
            "|2003  |2          |85  |\n",
            "|2003  |3          |95  |\n",
            "|2003  |4          |75  |\n",
            "|2004  |2          |80  |\n",
            "|2004  |3          |95  |\n",
            "|2004  |4          |95  |\n",
            "|2005  |2          |70  |\n",
            "|2005  |3          |85  |\n",
            "|2005  |4          |75  |\n",
            "+------+-----------+----+\n",
            "\n",
            "\n",
            "La unión de los datos de entrada de los cursos y las notas da el siguiente DataFrame: \n",
            "\n",
            "+--------+--------------------------+------+-----------+----+\n",
            "|Creditos|Carrera                   |Carnet|CodigoCurso|Nota|\n",
            "+--------+--------------------------+------+-----------+----+\n",
            "|4       |Ingenieria en Computadores|2000  |1          |95  |\n",
            "|4       |Ingenieria en Computadores|2000  |5          |90  |\n",
            "|3       |Ingenieria en Computadores|2000  |6          |80  |\n",
            "|4       |Ingenieria en Computadores|2001  |1          |90  |\n",
            "|4       |Ingenieria en Computadores|2001  |5          |70  |\n",
            "|3       |Ingenieria en Computadores|2001  |6          |75  |\n",
            "|4       |Ingenieria en Computadores|2002  |1          |85  |\n",
            "|4       |Ingenieria en Computadores|2002  |5          |95  |\n",
            "|3       |Ingenieria en Computadores|2002  |6          |75  |\n",
            "|3       |Ingenieria Electronica    |2003  |2          |85  |\n",
            "|3       |Ingenieria Electronica    |2003  |3          |95  |\n",
            "|2       |Ingenieria Electronica    |2003  |4          |75  |\n",
            "|3       |Ingenieria Electronica    |2004  |2          |80  |\n",
            "|3       |Ingenieria Electronica    |2004  |3          |95  |\n",
            "|2       |Ingenieria Electronica    |2004  |4          |95  |\n",
            "|3       |Ingenieria Electronica    |2005  |2          |70  |\n",
            "|3       |Ingenieria Electronica    |2005  |3          |85  |\n",
            "|2       |Ingenieria Electronica    |2005  |4          |75  |\n",
            "+--------+--------------------------+------+-----------+----+\n",
            "\n",
            "\n",
            "La unión de los datos de entrada de los cursos y las notas, junto con los datos de los estudiantes da el siguiente DataFrame: \n",
            "\n",
            "+----------------+--------------------------+--------+--------------------------+------+-----------+----+\n",
            "|NombreCompleto  |Carrera                   |Creditos|Carrera                   |Carnet|CodigoCurso|Nota|\n",
            "+----------------+--------------------------+--------+--------------------------+------+-----------+----+\n",
            "|Felipe Mejias   |Ingenieria en Computadores|4       |Ingenieria en Computadores|2000  |1          |95  |\n",
            "|Felipe Mejias   |Ingenieria en Computadores|4       |Ingenieria en Computadores|2000  |5          |90  |\n",
            "|Felipe Mejias   |Ingenieria en Computadores|3       |Ingenieria en Computadores|2000  |6          |80  |\n",
            "|Daniel Canessa  |Ingenieria en Computadores|4       |Ingenieria en Computadores|2001  |1          |90  |\n",
            "|Daniel Canessa  |Ingenieria en Computadores|4       |Ingenieria en Computadores|2001  |5          |70  |\n",
            "|Daniel Canessa  |Ingenieria en Computadores|3       |Ingenieria en Computadores|2001  |6          |75  |\n",
            "|Daniel Chacon   |Ingenieria en Computadores|4       |Ingenieria en Computadores|2002  |1          |85  |\n",
            "|Daniel Chacon   |Ingenieria en Computadores|4       |Ingenieria en Computadores|2002  |5          |95  |\n",
            "|Daniel Chacon   |Ingenieria en Computadores|3       |Ingenieria en Computadores|2002  |6          |75  |\n",
            "|Edgar Campos    |Ingenieria Electronica    |3       |Ingenieria Electronica    |2003  |2          |85  |\n",
            "|Edgar Campos    |Ingenieria Electronica    |3       |Ingenieria Electronica    |2003  |3          |95  |\n",
            "|Edgar Campos    |Ingenieria Electronica    |2       |Ingenieria Electronica    |2003  |4          |75  |\n",
            "|Roberto Bolanos |Ingenieria Electronica    |3       |Ingenieria Electronica    |2004  |2          |80  |\n",
            "|Roberto Bolanos |Ingenieria Electronica    |3       |Ingenieria Electronica    |2004  |3          |95  |\n",
            "|Roberto Bolanos |Ingenieria Electronica    |2       |Ingenieria Electronica    |2004  |4          |95  |\n",
            "|Esteban Ferarios|Ingenieria Electronica    |3       |Ingenieria Electronica    |2005  |2          |70  |\n",
            "|Esteban Ferarios|Ingenieria Electronica    |3       |Ingenieria Electronica    |2005  |3          |85  |\n",
            "|Esteban Ferarios|Ingenieria Electronica    |2       |Ingenieria Electronica    |2005  |4          |75  |\n",
            "+----------------+--------------------------+--------+--------------------------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas del estudiante con carnet: 2000 \n",
            "\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "|NombreCompleto|Carrera                   |Creditos|Carnet|CodigoCurso|Nota|\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "|Felipe Mejias |Ingenieria en Computadores|4       |2000  |1          |95  |\n",
            "|Felipe Mejias |Ingenieria en Computadores|4       |2000  |5          |90  |\n",
            "|Felipe Mejias |Ingenieria en Computadores|3       |2000  |6          |80  |\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas y los poderados por credito del estudiante con carnet: 2000 \n",
            "\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "|NombreCompleto|Carrera                   |Creditos|Carnet|CodigoCurso|Nota|CreditosxNotas|\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "|Felipe Mejias |Ingenieria en Computadores|4       |2000  |1          |95  |380           |\n",
            "|Felipe Mejias |Ingenieria en Computadores|4       |2000  |5          |90  |360           |\n",
            "|Felipe Mejias |Ingenieria en Computadores|3       |2000  |6          |80  |240           |\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas del estudiante con carnet: 2001 \n",
            "\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "|NombreCompleto|Carrera                   |Creditos|Carnet|CodigoCurso|Nota|\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "|Daniel Canessa|Ingenieria en Computadores|4       |2001  |1          |90  |\n",
            "|Daniel Canessa|Ingenieria en Computadores|4       |2001  |5          |70  |\n",
            "|Daniel Canessa|Ingenieria en Computadores|3       |2001  |6          |75  |\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas y los poderados por credito del estudiante con carnet: 2001 \n",
            "\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "|NombreCompleto|Carrera                   |Creditos|Carnet|CodigoCurso|Nota|CreditosxNotas|\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "|Daniel Canessa|Ingenieria en Computadores|4       |2001  |1          |90  |360           |\n",
            "|Daniel Canessa|Ingenieria en Computadores|4       |2001  |5          |70  |280           |\n",
            "|Daniel Canessa|Ingenieria en Computadores|3       |2001  |6          |75  |225           |\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas del estudiante con carnet: 2002 \n",
            "\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "|NombreCompleto|Carrera                   |Creditos|Carnet|CodigoCurso|Nota|\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "|Daniel Chacon |Ingenieria en Computadores|4       |2002  |1          |85  |\n",
            "|Daniel Chacon |Ingenieria en Computadores|4       |2002  |5          |95  |\n",
            "|Daniel Chacon |Ingenieria en Computadores|3       |2002  |6          |75  |\n",
            "+--------------+--------------------------+--------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas y los poderados por credito del estudiante con carnet: 2002 \n",
            "\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "|NombreCompleto|Carrera                   |Creditos|Carnet|CodigoCurso|Nota|CreditosxNotas|\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "|Daniel Chacon |Ingenieria en Computadores|4       |2002  |1          |85  |340           |\n",
            "|Daniel Chacon |Ingenieria en Computadores|4       |2002  |5          |95  |380           |\n",
            "|Daniel Chacon |Ingenieria en Computadores|3       |2002  |6          |75  |225           |\n",
            "+--------------+--------------------------+--------+------+-----------+----+--------------+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas del estudiante con carnet: 2003 \n",
            "\n",
            "+--------------+----------------------+--------+------+-----------+----+\n",
            "|NombreCompleto|Carrera               |Creditos|Carnet|CodigoCurso|Nota|\n",
            "+--------------+----------------------+--------+------+-----------+----+\n",
            "|Edgar Campos  |Ingenieria Electronica|3       |2003  |2          |85  |\n",
            "|Edgar Campos  |Ingenieria Electronica|3       |2003  |3          |95  |\n",
            "|Edgar Campos  |Ingenieria Electronica|2       |2003  |4          |75  |\n",
            "+--------------+----------------------+--------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas y los poderados por credito del estudiante con carnet: 2003 \n",
            "\n",
            "+--------------+----------------------+--------+------+-----------+----+--------------+\n",
            "|NombreCompleto|Carrera               |Creditos|Carnet|CodigoCurso|Nota|CreditosxNotas|\n",
            "+--------------+----------------------+--------+------+-----------+----+--------------+\n",
            "|Edgar Campos  |Ingenieria Electronica|3       |2003  |2          |85  |255           |\n",
            "|Edgar Campos  |Ingenieria Electronica|3       |2003  |3          |95  |285           |\n",
            "|Edgar Campos  |Ingenieria Electronica|2       |2003  |4          |75  |150           |\n",
            "+--------------+----------------------+--------+------+-----------+----+--------------+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas del estudiante con carnet: 2004 \n",
            "\n",
            "+---------------+----------------------+--------+------+-----------+----+\n",
            "|NombreCompleto |Carrera               |Creditos|Carnet|CodigoCurso|Nota|\n",
            "+---------------+----------------------+--------+------+-----------+----+\n",
            "|Roberto Bolanos|Ingenieria Electronica|3       |2004  |2          |80  |\n",
            "|Roberto Bolanos|Ingenieria Electronica|3       |2004  |3          |95  |\n",
            "|Roberto Bolanos|Ingenieria Electronica|2       |2004  |4          |95  |\n",
            "+---------------+----------------------+--------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas y los poderados por credito del estudiante con carnet: 2004 \n",
            "\n",
            "+---------------+----------------------+--------+------+-----------+----+--------------+\n",
            "|NombreCompleto |Carrera               |Creditos|Carnet|CodigoCurso|Nota|CreditosxNotas|\n",
            "+---------------+----------------------+--------+------+-----------+----+--------------+\n",
            "|Roberto Bolanos|Ingenieria Electronica|3       |2004  |2          |80  |240           |\n",
            "|Roberto Bolanos|Ingenieria Electronica|3       |2004  |3          |95  |285           |\n",
            "|Roberto Bolanos|Ingenieria Electronica|2       |2004  |4          |95  |190           |\n",
            "+---------------+----------------------+--------+------+-----------+----+--------------+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas del estudiante con carnet: 2005 \n",
            "\n",
            "+----------------+----------------------+--------+------+-----------+----+\n",
            "|NombreCompleto  |Carrera               |Creditos|Carnet|CodigoCurso|Nota|\n",
            "+----------------+----------------------+--------+------+-----------+----+\n",
            "|Esteban Ferarios|Ingenieria Electronica|3       |2005  |2          |70  |\n",
            "|Esteban Ferarios|Ingenieria Electronica|3       |2005  |3          |85  |\n",
            "|Esteban Ferarios|Ingenieria Electronica|2       |2005  |4          |75  |\n",
            "+----------------+----------------------+--------+------+-----------+----+\n",
            "\n",
            "Ahora se muestra el DataFrame con las notas y los poderados por credito del estudiante con carnet: 2005 \n",
            "\n",
            "+----------------+----------------------+--------+------+-----------+----+--------------+\n",
            "|NombreCompleto  |Carrera               |Creditos|Carnet|CodigoCurso|Nota|CreditosxNotas|\n",
            "+----------------+----------------------+--------+------+-----------+----+--------------+\n",
            "|Esteban Ferarios|Ingenieria Electronica|3       |2005  |2          |70  |210           |\n",
            "|Esteban Ferarios|Ingenieria Electronica|3       |2005  |3          |85  |255           |\n",
            "|Esteban Ferarios|Ingenieria Electronica|2       |2005  |4          |75  |150           |\n",
            "+----------------+----------------------+--------+------+-----------+----+--------------+\n",
            "\n",
            "Los promedios ponderados de los estudiantes son los siguientes: \n",
            "\n",
            "+----------------+--------------------------+-----------------+\n",
            "|NombreCompleto  |Carrera                   |PromedioPonderado|\n",
            "+----------------+--------------------------+-----------------+\n",
            "|Felipe Mejias   |Ingenieria en Computadores|89.0909090909091 |\n",
            "|Daniel Canessa  |Ingenieria en Computadores|78.63636363636364|\n",
            "|Daniel Chacon   |Ingenieria en Computadores|85.9090909090909 |\n",
            "|Edgar Campos    |Ingenieria Electronica    |86.25            |\n",
            "|Roberto Bolanos |Ingenieria Electronica    |89.375           |\n",
            "|Esteban Ferarios|Ingenieria Electronica    |76.875           |\n",
            "+----------------+--------------------------+-----------------+\n",
            "\n",
            "Los mejores  2 estudiantes de la carrera:  Ingenieria en Computadores \n",
            "\n",
            "+--------------+--------------------------+-----------------+\n",
            "|NombreCompleto|Carrera                   |PromedioPonderado|\n",
            "+--------------+--------------------------+-----------------+\n",
            "|Felipe Mejias |Ingenieria en Computadores|89.0909090909091 |\n",
            "|Daniel Chacon |Ingenieria en Computadores|85.9090909090909 |\n",
            "+--------------+--------------------------+-----------------+\n",
            "\n",
            "Los mejores  2 estudiantes de la carrera:  Ingenieria Electronica \n",
            "\n",
            "+---------------+----------------------+-----------------+\n",
            "|NombreCompleto |Carrera               |PromedioPonderado|\n",
            "+---------------+----------------------+-----------------+\n",
            "|Roberto Bolanos|Ingenieria Electronica|89.375           |\n",
            "|Edgar Campos   |Ingenieria Electronica|86.25            |\n",
            "+---------------+----------------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmMp47oJWrty",
        "colab_type": "text"
      },
      "source": [
        "# **6-) Pruebas Unitarias con Pytest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAGVvWuUXBgO",
        "colab_type": "text"
      },
      "source": [
        "**6.1) Instalar Pytest en Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ-NULniW0Wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "cf73cc27-0d4e-4c4c-aa29-e10b10612251"
      },
      "source": [
        "!pip install ipytest\n",
        "!pip install pytest"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ipytest) (19.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (2.4.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (19.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (1.12.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest) (7.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest) (1.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest) (41.6.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest) (19.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MkdGdL4XQd5",
        "colab_type": "text"
      },
      "source": [
        "**6.2) Importar Pytest y los comandos llamados magics para lograr correr Pytest en Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1277XV1bXcDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef19eedd-410f-475c-e9bc-b6328ec38fe7"
      },
      "source": [
        "import ipytest.magics\n",
        "import pytest\n",
        "import sys\n",
        "\n",
        "# This is needed in order to fix the __file__ issue that Google Colab throws\n",
        "__file__ = sys.argv[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzONRVcqXtrm",
        "colab_type": "text"
      },
      "source": [
        "**6.3) Pruebas unitarias para la unión de datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UypeUstPX-E6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "e27e3671-41e8-4fb7-e505-de0cbb16ea4a"
      },
      "source": [
        "# This command is needed to run the UTs in Google Colab\n",
        "%%run_pytest[clean] -qq\n",
        "\n",
        "def test_create_succesful_spark_session():\n",
        "    assert create_spark_session() is not None\n",
        "\n",
        "def test_create_spark_data_frame_from_none_csv_file_path():\n",
        "    non_existent_csv_url_path = \"https://raw.githubusercontent.com/fmejias/CienciasDeLosDatosTEC/master/BigData/Tareas/Tarea1/estudiante2.csv\"\n",
        "    with pytest.raises((HTTPError, Exception)):\n",
        "      create_spark_data_frame_from_csv_file(non_existent_csv_url_path)\n",
        "\n",
        "def test_create_spark_data_frame_from_students_csv_file_path():\n",
        "    student_spark_data_frame = create_spark_data_frame_from_csv_file(STUDENTS_CSV_PATH)\n",
        "    assert student_spark_data_frame is not None\n",
        "    assert isinstance(student_spark_data_frame, dataframe.DataFrame)\n",
        "\n",
        "def test_create_spark_data_frame_from_courses_csv_file_path():\n",
        "    courses_spark_data_frame = create_spark_data_frame_from_csv_file(COURSE_CSV_PATH)\n",
        "    assert courses_spark_data_frame is not None\n",
        "    assert isinstance(courses_spark_data_frame, dataframe.DataFrame)\n",
        "\n",
        "def test_create_spark_data_frame_from_grades_csv_file_path():\n",
        "    grades_spark_data_frame = create_spark_data_frame_from_csv_file(GRADES_CSV_PATH)\n",
        "    assert grades_spark_data_frame is not None\n",
        "    assert isinstance(grades_spark_data_frame, dataframe.DataFrame)\n",
        "\n",
        "# Execute these UTs\n",
        "ipytest.run_tests()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unittest.case.FunctionTestCase (test_create_spark_data_frame_from_courses_csv_file_path) ... "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+-----------+--------+--------------------------+\n",
            "|CodigoCurso|Creditos|Carrera                   |\n",
            "+-----------+--------+--------------------------+\n",
            "|1          |4       |Ingenieria en Computadores|\n",
            "|2          |3       |Ingenieria Electronica    |\n",
            "|3          |3       |Ingenieria Electronica    |\n",
            "|4          |2       |Ingenieria Electronica    |\n",
            "|5          |4       |Ingenieria en Computadores|\n",
            "|6          |3       |Ingenieria en Computadores|\n",
            "+-----------+--------+--------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "unittest.case.FunctionTestCase (test_create_spark_data_frame_from_grades_csv_file_path) ... "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+------+-----------+----+\n",
            "|Carnet|CodigoCurso|Nota|\n",
            "+------+-----------+----+\n",
            "|2000  |1          |95  |\n",
            "|2000  |5          |90  |\n",
            "|2000  |6          |80  |\n",
            "|2001  |1          |90  |\n",
            "|2001  |5          |70  |\n",
            "|2001  |6          |75  |\n",
            "|2002  |1          |85  |\n",
            "|2002  |5          |95  |\n",
            "|2002  |6          |75  |\n",
            "|2003  |2          |85  |\n",
            "|2003  |3          |95  |\n",
            "|2003  |4          |75  |\n",
            "|2004  |2          |80  |\n",
            "|2004  |3          |95  |\n",
            "|2004  |4          |95  |\n",
            "|2005  |2          |70  |\n",
            "|2005  |3          |85  |\n",
            "|2005  |4          |75  |\n",
            "+------+-----------+----+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "unittest.case.FunctionTestCase (test_create_spark_data_frame_from_none_csv_file_path) ... ok\n",
            "unittest.case.FunctionTestCase (test_create_spark_data_frame_from_students_csv_file_path) ... "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+------+----------------+--------------------------+\n",
            "|Carnet|NombreCompleto  |Carrera                   |\n",
            "+------+----------------+--------------------------+\n",
            "|2000  |Felipe Mejias   |Ingenieria en Computadores|\n",
            "|2001  |Daniel Canessa  |Ingenieria en Computadores|\n",
            "|2002  |Daniel Chacon   |Ingenieria en Computadores|\n",
            "|2003  |Edgar Campos    |Ingenieria Electronica    |\n",
            "|2004  |Roberto Bolanos |Ingenieria Electronica    |\n",
            "|2005  |Esteban Ferarios|Ingenieria Electronica    |\n",
            "+------+----------------+--------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "unittest.case.FunctionTestCase (test_create_succesful_spark_session) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 1.405s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".....                                                                    [100%]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}