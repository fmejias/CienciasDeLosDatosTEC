{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoVzbpenBYwm"
   },
   "source": [
    "# **Programa Ciencia de los Datos**\n",
    "## **Curso Minería de datos e Inteligencia de Negocios**\n",
    "\n",
    "## **Proyecto final**\n",
    "\n",
    "- Profesora: Lorena Zuñiga\n",
    "\n",
    "- Estudiantes:  \n",
    "    - Felipe Alberto Mejías Loría, Instituto Tecnológico de Costa Rica.\n",
    "    - María Auxiliadora Mora, Instituto Tecnológico de Costa Rica.\n",
    "\n",
    "- Marzo de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQgIG3GtxDiv"
   },
   "source": [
    "# **Predicción de cantidad de delitos por zona en Costa Rica utilizando algoritmos de Aprendizaje Automático**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1IA13JJDBv_"
   },
   "source": [
    "# **Configuración inicial del ambiente para el desarrollo del Proyecto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qs-P6HvvD4Nz"
   },
   "source": [
    "## 1-) Instalación de PySpark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmdZlUMiD4N2"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries. The user must change the variable SPARK_HOME according her environment.\n",
    "import findspark\n",
    "\n",
    "# Set SPARK_HOME. Needed to initialize Apache Spark.\n",
    "SPARK_PATH = 'C:\\Users\\mejiasf\\Desktop\\Spark\\spark-2.4.4-bin-hadoop2.7'\n",
    "\n",
    "findspark.init(SPARK_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27cF0odKD4N5"
   },
   "source": [
    "## 2-) Importar bibliotecas necesarias para la ejecución del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcwNBU97D4N6"
   },
   "outputs": [],
   "source": [
    "# Necessary Imports for the execution of the TP3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import findspark\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, Row, dataframe\n",
    "from pyspark.sql.functions import col, date_format, udf, array, explode, trim, lower, ltrim, rtrim\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.types import (StringType, IntegerType, FloatType, \n",
    "                               DecimalType, StructField, StructType)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector, Vectors, VectorUDT\n",
    "\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LMXs_iMD4N-"
   },
   "source": [
    "## 3-) Funciones utilitarias para la construcción de DataFrames y otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pizLjs4D4N_"
   },
   "outputs": [],
   "source": [
    "POSTGRESQL_URL = \"jdbc:postgresql://localhost/\"\n",
    "POSTGRESQL_USER = \"postgres\"\n",
    "POSTGRESQL_PASSWORD = \"big_data\"\n",
    "\n",
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    This function builds a Spark Session\n",
    "    return the main entry of a Spark DataFrame\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "      .builder \\\n",
    "      .appName(\"Basic JDBC pipeline\") \\\n",
    "      .config(\"spark.driver.extraClassPath\", \"postgresql-42.1.4.jar\") \\\n",
    "      .config(\"spark.executor.extraClassPath\", \"postgresql-42.1.4.jar\") \\\n",
    "      .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "def join_spark_data_frames(data_frame_1, data_frame_2,\n",
    "                           using_column_data_frame_1,\n",
    "                           using_column_data_frame_2):\n",
    "    \"\"\"\n",
    "    This function joint two Spark Data Frames\n",
    "    data_frame_1: Spark DataFrame 1\n",
    "    data_frame_2: Spark DataFrame 2\n",
    "    using_column_data_frame_1: Column from DataFrame 1 to compare\n",
    "    using_column_data_frame_2: Column from DataFrame 2 to compare\n",
    "    return the Spark DataFrame from the JOIN\n",
    "    \"\"\"\n",
    "    using_columns_statement = using_column_data_frame_1 == using_column_data_frame_2\n",
    "    joint_data_frame = data_frame_1.join(data_frame_2, using_columns_statement)\n",
    "\n",
    "    # To remove duplicated columns\n",
    "    joint_data_frame = joint_data_frame.drop(using_column_data_frame_1)\n",
    "\n",
    "    return joint_data_frame\n",
    "\n",
    "def write_spark_df_to_db(spark_df, table_name):\n",
    "    \"\"\"\n",
    "    This function writes Spark dataframe to DB\n",
    "    \"\"\"\n",
    "    spark_df \\\n",
    "        .write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .mode('overwrite') \\\n",
    "        .option(\"url\", POSTGRESQL_URL) \\\n",
    "        .option(\"user\", POSTGRESQL_USER) \\\n",
    "        .option(\"password\", POSTGRESQL_PASSWORD) \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .save()\n",
    "\n",
    "def read_dataset_from_db(spark_session, table_name):\n",
    "    \"\"\"\n",
    "    This function reads the clean dataset from the database\n",
    "    \"\"\"\n",
    "    spark_df = spark_session \\\n",
    "               .read \\\n",
    "               .format(\"jdbc\") \\\n",
    "               .option(\"url\", POSTGRESQL_URL) \\\n",
    "               .option(\"user\", POSTGRESQL_USER) \\\n",
    "               .option(\"password\", POSTGRESQL_PASSWORD) \\\n",
    "               .option(\"dbtable\", table_name) \\\n",
    "               .load()\n",
    "    spark_df.show()\n",
    "    return spark_df\n",
    "\n",
    "def convert_categorical_values_to_numerical_from_df(spark_df, categorical_columns_list):\n",
    "    \"\"\"\n",
    "    This function creates a Spark DataFrame with all values as numerical\n",
    "    spark_df: Spark DataFrame\n",
    "    return the Spark DataFrame with all values as numerical\n",
    "    \"\"\"\n",
    "    # Convert categorical columns to numerical values\n",
    "    for categorical_column in categorical_columns_list:\n",
    "        new_column_name = \"{column_name}_index\".format(column_name = categorical_column)\n",
    "        indexer = StringIndexer(inputCol=categorical_column, outputCol=new_column_name)\n",
    "        spark_df = indexer.fit(spark_df).transform(spark_df)\n",
    "    \n",
    "    # Remove categorical columns\n",
    "    columns_to_drop = categorical_columns_list\n",
    "    spark_df = spark_df.drop(*columns_to_drop)\n",
    "    \n",
    "    # Rename new numerical columns\n",
    "    for categorical_column in categorical_columns_list:\n",
    "        new_column_name = \"{column_name}_index\".format(column_name = categorical_column)\n",
    "        spark_df = spark_df.withColumnRenamed(new_column_name, categorical_column)\n",
    "    \n",
    "    # Show converted data\n",
    "    print(\"- Se demuestra que los datos se han convertido con éxito de tipo categórico a tipo numérico: \\n\")\n",
    "    spark_df.select(categorical_columns_list).show()\n",
    "\n",
    "    return spark_df\n",
    "\n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=((rect.get_x() + rect.get_width() / 2), height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    \n",
    "def count_delitos(spark_session, oij_spark_df):\n",
    "    \"\"\"\n",
    "    This function counts crimes grouped by the Canton, Delito, Sub-delito and Hora columns\n",
    "    \"\"\"\n",
    "    \n",
    "    oij_spark_df= oij_spark_df.groupBy(\"Canton\", \"Delito\", \"SubDelito\",\"Hora\",  \"Victima\", \"Genero\", \"Nacionalidad\").count()\n",
    "\n",
    "    print(\"Cuenta de delitos agrupados por las columnas Canton, Delito, SubDelito, Hora\")\n",
    "\n",
    "    print(oij_spark_df.show())\n",
    "\n",
    "    return oij_spark_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1NqG1ccSHjg3"
   },
   "source": [
    "# **I) Fase de entendimiento del negocio**\n",
    "\n",
    "## a) Determinar los objetivos de negocio\n",
    "\n",
    "Antecedentes\n",
    "\n",
    "La minería de datos y el aprendizaje automático han sido utilizados de forma exitosa en múltiples proyectos orientados a la detección y prevención de delitos (McClendon y Meghanathan, 2015). Investigaciones previas en análisis de datos asociados a delitos han concluido que algunos factores, como son la educación, la pobreza y el desempleo pueden influir en el aumento o disminución de la tasa de delitos de una región (Suhong, Param, Parminder y Pooya, 2018). El objetivo del presente proyecto es utilizar datos de criminalidad en Costa Rica combinados con datos socioeconómicos asociados a cantones para demostrar cuán efectivos y precisos pueden ser los algoritmos de aprendizaje automático en la predicción de delitos a nivel nacional. \n",
    "\n",
    "En Costa Rica, el Organismo de Investigación Judicial (OIJ) es la institución encargada del descubrimiento y verificación científica de los delitos y sus presuntos responsables. El OIJ publica datos sobre criminalidad en Costa Rica que tienen como fuente las denuncias interpuestas directamente ante esta entidad nacional. Los datos recopilados por el OIJ están disponibles por provincia o cantón. Los datos socioeconómicos que se utilizarán en el proyecto fueron generados por el Instituto Nacional de Estadística y Censos de Costa Rica (INEC) en el censo nacional del 2011. \n",
    "\n",
    "El OIJ cuenta con una Unidad de Análisis Criminal desde el año 2003. Esta unidad, se encarga de: Planificar, coordinar, supervisar, y evaluar las labores profesionales y administrativas, complejas de análisis criminal para apoyar la planificación estratégica y operativa de la acción policial contra el delito.\n",
    "La Unidad de Análisis Criminal recientemente identificó la minería de datos y el aprendizaje automático como un mecanismo para realizar análisis y generar modelos que les permita predecir la cantidad y tipos de delitos por región geográfica que puedan ocurrir en el futuro dependiendo de diversas condiciones, principalmente socio-económicas.\n",
    "\n",
    "### Objetivos de negocio\n",
    "Los objetivos más importantes, son: \n",
    "1. Investigación delitos, identificar y aprehender preventivamente a los presuntos culpables. \n",
    "2. Reunir, asegurar y ordenar científicamente las pruebas y demás antecedentes necesarios para la investigación.\n",
    "3. Ejecutar labores profesionales relacionadas con el análisis de hechos punibles, estadística criminal, sospechosos y otros similares; \n",
    "4. Colaborar en el establecimiento de nuevos métodos de trabajo y en la dirección de las labores de inteligencia policial.\n",
    "5. Recopilar, evaluar, procesar, analizar y comunicar información general o concreta sobre la actividad criminal, con el fin de apoyar la planificación estratégica y operativa de la acción policial contra el delito, realizar análisis comparativos de casos, de fenómenos criminales, de grupos de autores, entre otros.\n",
    "\n",
    "Los objetivos particulares de la  Unidad de Análisis Criminal son utilizar mejor los recursos de la institución, por medio de: \n",
    "- Identificar puntos calientes del crimen y asignar recursos de vigilancia acordes con los tipos de delito.\n",
    "- Reorganizar patrullajes acordes con sitios de vulnerabilidad.\n",
    "y prevenir el crimen, por medio de:\n",
    "- Educar a la población.\n",
    "- Desarrollar capacidades en los encargados de combatirlo. \n",
    "\n",
    "Para el proyecto de minería se seleccionó trabajar con el objetivo cinco del negocio, que está muy relacionado con los objetivos de la Unidad de Análisis Criminal, específicamente en el análisis de datos de criminalidad con el fin de apoyar la planificación estratégica y operativa de la acción policial contra el delito. Se seleccionó este objetivo, para incursionar en una primera fase en el tema de minería de datos e inteligencia de negocios, adicionalmente, se estimó que con los datos que se cuenta en la actualidad se puede lograr un buen resultado en este objetivo. \n",
    "\n",
    "### Criterios de éxito (en términos de negocio)\n",
    "\n",
    "Desde el punto de vista del negocio se establece como criterio de éxito la posibilidad de realizar predicciones certeras sobre la cantidad de delitos que ocurren a nivel de cantón en el territorio nacional, de tal forma que la Unidad de Análisis Criminal pueda planificar en el tiempo los recursos (ie. personal, patrullas, motos) a asignar por zona. Se evaluará los resultados de predicción del modelo seleccionando un porcentaje de los datos únicamente para realizar pruebas. \n",
    "\n",
    "## b) Evaluación de la situación actual\n",
    "Inventario de recursos (datos, personal, TI)\n",
    "- Personas: el equipo del proyecto cuenta con experiencia en extracción, almacenamiento, carga y limpieza de datos. Además, cuenta con el conocimiento necesario para generar predicciones a partir de esos datos depurados.\n",
    "- Datos: dado que el proyecto necesita utilizar datos de criminalidad en combinación con datos socioeconómicos, actualmente en Costa Rica el OIJ y INEC ofrecen datos abiertos a todo público con información de estos dos temas. Ambas instituciones permiten descargar esta información en diferentes tipos de archivos y no requieren de permisos especiales para acceder a esos datos.\n",
    "- Hardware: Ambos integrantes del equipo cuentan con computadoras capaces de manejar grandes datasets y al mismo tiempo manejar un proyecto de Data Science. Ambas computadoras cuentan con las siguientes especificaciones:\n",
    "   - 16 GB de RAM, lo cual permite un procesamiento muy rápido de los algoritmos de machine learning.\n",
    "   - NVIDIA GPU, por si es necesario llegar a utilizar bibliotecas de Deep Learning.\n",
    "   - Un procesador Intel i7.\n",
    "   - 1 TB de Disco Duro.\n",
    "- Software: Ambos integrantes del equipo cuentan con las siguientes herramientas de Data Mining:\n",
    "   - Excel\n",
    "   - ggplot2\n",
    "   - Tableau\n",
    "   - Jupyter\n",
    "\n",
    "### Requerimientos\n",
    "\n",
    "- Un requerimiento importante del proyecto es que las fuentes de datos consultadas sean abiertas para todo el público.\n",
    "- El proyecto debe ser de tipo Open Source. Esto con el fin de que cualquier persona que quiera extender el alcance del proyecto pueda hacerlo sin ningún tipo de restricción.\n",
    "- Los datos extraídos de las fuentes de datos deben venir en un archivo de tipo CSV.\n",
    "- El lenguaje de programación que se debe utilizar para cargar, limpiar y manipular los datos deber ser R.\n",
    "- Los resultados arrojados por cada una de las etapas de carga, limpieza, manipulación y predicciones debe ser presentado en un archivo HTML que contenga el código utilizado y la salida de cada etapa.\n",
    "- Ambos conjuntos de datos se deben manejar como un solo conjunto de datos por lo que deben poder unirse.\n",
    "\n",
    "\n",
    "### Supuestos\n",
    "\n",
    "Uno de los principales supuestos es que los datos extraídos del OIJ y del INEC vienen sin datos faltantes y que todos los valores que vienen en los campos tienen un valor significativo.\n",
    "\n",
    "### Restricciones\n",
    "\n",
    "La única restricción con la que va a contar el proyecto es que únicamente se deben analizar los datos correspondientes al año 2011.\n",
    "\n",
    "### Riesgos y contingencias\n",
    "\n",
    "- Riesgo: Uno de los riesgos que se corre es que el alcance del proyecto sea muy grande y no se logre cumplir con los plazos establecidos para cada etapa.\n",
    "- Plan de contingencia: Se debería reducir el alcance de este a un subconjunto de los resultados que se pretendían alcanzar.\n",
    "- Riesgo: Se corre el riesgo que los datos obtenidos del OIJ y del INEC vengan con datos faltantes, con columnas que sean las mismas pero vengan escritas de manera diferente en ambos fuentes de datos y que por tanto dificulten la unión de ellos mismos.\n",
    "- Plan de contingencia: Buscar otra fuente de datos de la que se obtenga información con mayor calidad y que permita llevar a cabo el proyecto con mayor velocidad. \n",
    "\n",
    "### Beneficios\n",
    "\n",
    "- Uno de los beneficios de la predicción de delitos es utilizar mejor los recursos. La predicción de delitos va a permitir identificar puntos calientes del crimen y asignar recursos de vigilancia acordes con los tipos de delito.\n",
    "- Otro de los beneficios es que va a permitir prevenir el crimen.\n",
    "\n",
    "\n",
    "## c) Objetivos de minería de datos \n",
    "\n",
    "El objetivo del proyecto de minería de datos es analizar datos socioeconómicos y de criminalidad en Costa Rica para predecir la cantidad de delitos por zona que puedan ocurrir en el futuro dependiendo de diversas condiciones, principalmente socio-económicas.\n",
    "\n",
    "\n",
    "### Criterios de éxito (desde la perspectiva de minería de datos)\n",
    "Desde el punto de vista de la minería de datos se establece como criterio de éxito el lograr predicciones sobre cantidad de delitos por zona con un elevado porcentaje de fiabilidad, concretamente definimos este porcentaje en al menos un 85%. \n",
    "\n",
    "\n",
    "## d) Plan del proyecto\n",
    "\n",
    "| Fase                       \t| Duración \t| Recursos                  \t| Riesgos                                         \t|   \t|\n",
    "|----------------------------\t|----------\t|---------------------------\t|-------------------------------------------------\t|---\t|\n",
    "| Entendimiento del negocio  \t| 1 semana \t| Ambos miembros del equipo \t| Cambio en la estrategia                         \t|   \t|\n",
    "| Entendimiento de los datos \t| 1 semana \t| Ambos miembros del equipo \t| Problemas con la calidad de los datos obtenidos \t|   \t|\n",
    "| Preparación de los datos   \t| 1 semana \t| Ambos miembros del equipo \t| Problemas con la calidad de los datos obtenidos \t|   \t|\n",
    "| Modelado                   \t| 1 semana \t| Ambos miembros del equipo \t| Problemas escogiendo el modelo adecuado         \t|   \t|\n",
    "| Evaluación                 \t| 1 semana \t| Ambos miembros del equipo \t| Dificultad para implementar los resultados      \t|   \t|\n",
    "| Deployment                 \t| 1 semana \t| Ambos miembros del equipo \t| Dificultad para implementar los resultados      \t|   \t|\n",
    "\n",
    "\n",
    "### Evaluación inicial de herramientas y técnicas\n",
    "\n",
    "Herramienta de programación R: R se va utilizar para escribir programas con fines estadísticos y analíticos para minería de datos. Esta herramienta permite analizar gráficos, cargar, limpiar, manipular, clasificar y analizar datos. R provee todas las funciones necesarias para el proyecto a implementar.\n",
    "\n",
    "Las técnicas de Minería de Datos a utilizar serían:\n",
    "- Decision Tree Regression: El árbol de decisión es uno de los algoritmos más utilizados para las tareas de clasificación. Los árboles de decisión se usan ampliamente ya que son fáciles de interpretar y permiten manejar características categóricas.\n",
    "- Random Forest Regression: El Random Forest es un método muy bueno, robusto y versátil para las tareas de regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7tWkwfZ8rOx"
   },
   "source": [
    "# **II) Fase de entendimiento de los datos**\n",
    "\n",
    "## a) Recopilación inicial de datos\n",
    "Lista de datasets requeridos\n",
    "\n",
    "- Datos sobre criminalidad en Costa Rica\n",
    "\n",
    "- Datos socioeconómicos  del año 2011 generados para todo el país.\n",
    "\n",
    "\n",
    "### Ubicación de los datasets\n",
    "\n",
    "- Los datos sobre criminalidad en Costa Rica provienen del OIJ, estos tienen como fuente las denuncias interpuestas directamente ante esta entidad nacional. \n",
    "\n",
    "- Los datos socioeconómicos del 2011 fueron generados por el INEC. El INEC es la institución encargada a nivel nacional de la generación y divulgación de datos estadísticos obtenidos por medio de censos, encuestas y otros estudios sobre demografía, economía y otros. Al igual que en el OIJ los datos están disponibles por cantón.\n",
    "\n",
    "\n",
    "\n",
    "### Método de acceso\n",
    "\n",
    "Ambos conjuntos de datos están disponibles en el sitio web de cada institución. Los datos van a ser bajados del sitio en archivos csv e importados al ambiente de trabajo antes de procesarlos. \n",
    "\n",
    "## b) Descripción de los datos\n",
    "\n",
    "El conjunto de datos de criminalidad del OIJ posee las siguientes columnas:\n",
    "  - Delito:Tipo de Delito\n",
    "  - SubDelito: Tipo de SubDelito\n",
    "  - Fecha: Fecha del Hecho\n",
    "  - Hora: Rango de 3 horas del Hecho\n",
    "  - Victima: Descripción de la Víctima\n",
    "  - SubVictima: Descripción de la SubVíctima\n",
    "  - Edad: Grupo de Edad que pertenece la Víctima\n",
    "  - Genero: Género de la Víctima\n",
    "  - Nacionalidad: Nacionalidad de la Víctima\n",
    "  - Provincia: Provincia del Lugar del Hecho\n",
    "  - Canton: Cantón del Lugar del Hecho\n",
    "  - Distrito: Distrito del Lugar del Hecho\n",
    "\n",
    "\n",
    "Los tipos de delitos definidos por el OIJ y documentados en el conjunto de datos son los siguientes (OIJ, 2018):\n",
    "  - Asalto: Desapoderamiento ilegítimo con violencia sobre las personas de alguna de sus pertenencias. Consiste en llevarse o intentar llevarse en circunstancias de confrontación cualquier cosa de valor que se encuentra bajo el control, custodia o cuidado de otra persona. En estos casos quienes ejercen esta acción utilizan la fuerza o amenaza de fuerza o violencia o ponen a la víctima en temor de daño inmediato.\n",
    "  - Hurto: Consiste en apoderarse de un bien sin utilizar fuerza en las cosas o violencia sobre las personas. De presentarse estos elementos (fuerza y violencia) estaríamos en presencia de un robo o un asalto.\n",
    "  - Robo: Es la entrada ilícita ejerciendo fuerza sobre las cosas a una casa de habitación, bodega, local comercial, institución, otros.\n",
    "  - Tacha de vehículo: Es la sustracción mediante el ingreso ilícito al automotor utilizando mecanismos de fuerza para sustraer pertenencias dentro del automóvil.\n",
    "  - Robo de Vehículo: Es el robo de un medio de transporte.\n",
    "  - Homicidio: Hecho delictivo que consiste en la privación de la vida de otra persona.\n",
    "\n",
    "El segundo conjunto de datos contiene información sobre indicadores económicos, según provincia y cantón. Los datos fueron generados por el INEC como resultado del censo realizado en el país en el año 2011. El conjunto de datos posee las siguientes columnas:\n",
    "\n",
    " - Provincia, Cantón y Distrito\n",
    " - Población de 15 años y más\n",
    " - Tasa neta de participación\n",
    " - Tasa de ocupación\n",
    " - Tasa de desempleo abierto\n",
    " - Porcentaje de población económicamente inactiva\n",
    " - Relación de dependencia económica\n",
    "\n",
    "Las siguientes funciones despliegan los datos del OIJ e INEC:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lByjoBuABqa5"
   },
   "source": [
    "# **Código en Python para la descripción de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-8jsqcQCbKE"
   },
   "source": [
    "## Funciones encargadas de la carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_dataframe_from_csv(spark_session,\n",
    "                                    csv_file_name,\n",
    "                                    schema_types_list):\n",
    "    \"\"\"\n",
    "    This function creates a Spark DataFrame from Dataset CSV file\n",
    "    spark_session: Spark Session\n",
    "    return the Spark DataFrame\n",
    "    \"\"\"\n",
    "    print(\"\\n- Cargando archivo de entrada CSV: {name}\".format(name = csv_file_name))\n",
    "    \n",
    "    spark_df = spark_session \\\n",
    "      .read \\\n",
    "      .format(\"csv\") \\\n",
    "      .option(\"path\", csv_file_name) \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(StructType(schema_types_list)) \\\n",
    "      .load()\n",
    "    \n",
    "    # Rename OIJ Spark DataFrame Columns\n",
    "    spark_df = rename_oij_spark_dataframe_columns(spark_df) \\\n",
    "               if csv_file_name == \"datos_delitos_oij_2011.csv\" \\\n",
    "               else spark_df\n",
    "    \n",
    "    return spark_df\n",
    "\n",
    "def rename_oij_spark_dataframe_columns(spark_df):\n",
    "    \"\"\"\n",
    "    This function is necessary as OIJ Dataset is outdated since the CSV\n",
    "    they provide does not bring the time field\n",
    "    spark_df: Spark DataFrame\n",
    "    return the Spark DataFrame with right columns names\n",
    "    \"\"\"\n",
    "    spark_df = spark_df.withColumnRenamed('Victima', 'Hora')\n",
    "    spark_df = spark_df.withColumnRenamed('SubVictima', 'Victima')\n",
    "    spark_df = spark_df.withColumnRenamed('Edad', 'SubVictima')\n",
    "    spark_df = spark_df.withColumnRenamed('Genero', 'Edad')\n",
    "    spark_df = spark_df.withColumnRenamed('Nacionalidad', 'Genero')\n",
    "    spark_df = spark_df.withColumnRenamed('Provincia', 'Nacionalidad')\n",
    "    spark_df = spark_df.withColumnRenamed('Canton', 'Provincia')\n",
    "    spark_df = spark_df.withColumnRenamed('Distrito', 'Canton')\n",
    "    return spark_df\n",
    "\n",
    "def show_spark_dataframe(spark_df, columns_list):\n",
    "    \"\"\"\n",
    "    This function completes data before training model\n",
    "    \"\"\"\n",
    "    print(\"\\n1-) Tipos de datos: \\n\")\n",
    "    spark_df.printSchema()\n",
    "    \n",
    "    print(\"2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \\n\")\n",
    "    spark_df.select(columns_list).show()\n",
    "\n",
    "def load_inec_data(spark_session):\n",
    "    \"\"\"\n",
    "    This function loads INEC CSV data\n",
    "    \"\"\"\n",
    "    schema_types_list = [StructField(\"Canton\", StringType()),\n",
    "                         StructField(\"Poblacion de 15 anos y mas\", IntegerType()),\n",
    "                         StructField(\"Tasa neta de participacion\", FloatType()),\n",
    "                         StructField(\"Tasa de ocupacion\", FloatType()),\n",
    "                         StructField(\"Tasa de desempleo abierto\", FloatType()),\n",
    "                         StructField(\"Porcentaje de poblacion economicamente inactiva\", FloatType()),\n",
    "                         StructField(\"Relacion de dependencia economica\", FloatType()),\n",
    "                         StructField(\"Porcentaje de poblacion ocupada - Sector Primario\", FloatType()),\n",
    "                         StructField(\"Porcentaje de poblacion ocupada - Sector Secundario\", FloatType()),\n",
    "                         StructField(\"Porcentaje de poblacion ocupada - Sector Terciario\", FloatType())]\n",
    "    \n",
    "    inec_spark_df = create_spark_dataframe_from_csv(spark_session,\n",
    "                                                    \"datos_socioeconomicos_inec_2011.csv\",\n",
    "                                                    schema_types_list)\n",
    "    return inec_spark_df\n",
    "\n",
    "def load_oij_data(spark_session):\n",
    "    \"\"\"\n",
    "    This function loads OIJ CSV data\n",
    "    \"\"\"\n",
    "    schema_types_list = [StructField(\"Delito\", StringType()),\n",
    "                         StructField(\"SubDelito\", StringType()),\n",
    "                         StructField(\"Fecha\", StringType()),\n",
    "                         StructField(\"Victima\", StringType()),\n",
    "                         StructField(\"SubVictima\", StringType()),\n",
    "                         StructField(\"Edad\", StringType()),\n",
    "                         StructField(\"Genero\", StringType()),\n",
    "                         StructField(\"Nacionalidad\", StringType()),\n",
    "                         StructField(\"Provincia\", StringType()),\n",
    "                         StructField(\"Canton\", StringType()),\n",
    "                         StructField(\"Distrito\", StringType())]\n",
    "    \n",
    "    oij_spark_df = create_spark_dataframe_from_csv(spark_session,\n",
    "                                                   \"datos_delitos_oij_2011.csv\",\n",
    "                                                   schema_types_list)\n",
    "    \n",
    "    return oij_spark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-8jsqcQCbKE"
   },
   "source": [
    "## Funciones encargadas de la descripción de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jajJhazhHjhc",
    "outputId": "b891bc52-de21-4404-c2f6-2d9c3cbce616",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- Carga inicial de los datos:\n",
      "\n",
      "- Cargando archivo de entrada CSV: datos_delitos_oij_2011.csv\n",
      "\n",
      "1-) Tipos de datos: \n",
      "\n",
      "root\n",
      " |-- Delito: string (nullable = true)\n",
      " |-- SubDelito: string (nullable = true)\n",
      " |-- Fecha: string (nullable = true)\n",
      " |-- Hora: string (nullable = true)\n",
      " |-- Victima: string (nullable = true)\n",
      " |-- SubVictima: string (nullable = true)\n",
      " |-- Edad: string (nullable = true)\n",
      " |-- Genero: string (nullable = true)\n",
      " |-- Nacionalidad: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Canton: string (nullable = true)\n",
      "\n",
      "2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \n",
      "\n",
      "+------+-----------+------+-------------+\n",
      "|Delito|  SubDelito|Genero|       Canton|\n",
      "+------+-----------+------+-------------+\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   ALAJUELITA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     OREAMUNO|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|      HEREDIA|\n",
      "|ASALTO|ARMA BLANCA| MUJER|      HEREDIA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|      LIBERIA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     SAN JOSE|\n",
      "|ASALTO|ARMA BLANCA| MUJER|   GOICOECHEA|\n",
      "|ASALTO|ARMA BLANCA| MUJER|MONTES DE OCA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     SAN JOSE|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   CURRIDABAT|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|PEREZ ZELEDON|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|        LIMON|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|        LIMON|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     SAN JOSE|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE| DESAMPARADOS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   PUNTARENAS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   PUNTARENAS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|       MATINA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   PUNTARENAS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|      LIBERIA|\n",
      "+------+-----------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "3- La cantidad de registros del OIJ es: 47476 \n",
      "\n",
      "- Cargando archivo de entrada CSV: datos_socioeconomicos_inec_2011.csv\n",
      "\n",
      "1-) Tipos de datos: \n",
      "\n",
      "root\n",
      " |-- Canton: string (nullable = true)\n",
      " |-- Poblacion de 15 anos y mas: integer (nullable = true)\n",
      " |-- Tasa neta de participacion: float (nullable = true)\n",
      " |-- Tasa de ocupacion: float (nullable = true)\n",
      " |-- Tasa de desempleo abierto: float (nullable = true)\n",
      " |-- Porcentaje de poblacion economicamente inactiva: float (nullable = true)\n",
      " |-- Relacion de dependencia economica: float (nullable = true)\n",
      " |-- Porcentaje de poblacion ocupada - Sector Primario: float (nullable = true)\n",
      " |-- Porcentaje de poblacion ocupada - Sector Secundario: float (nullable = true)\n",
      " |-- Porcentaje de poblacion ocupada - Sector Terciario: float (nullable = true)\n",
      "\n",
      "2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \n",
      "\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "|             Canton|Poblacion de 15 anos y mas|Tasa de desempleo abierto|\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "|           San Jose|                    225856|                      3.9|\n",
      "|             Escazu|                     44797|                      3.0|\n",
      "|       Desamparados|                    159292|                      4.0|\n",
      "|           Puriscal|                     25774|                      3.1|\n",
      "|            Tarrazu|                     11800|                      2.8|\n",
      "|             Aserri|                     43396|                      3.2|\n",
      "|               Mora|                     20414|                      3.2|\n",
      "|         Goicoechea|                     90537|                      3.7|\n",
      "|          Santa Ana|                     38096|                      2.3|\n",
      "|         Alajuelita|                     56704|                      3.8|\n",
      "|Vazquez de Coronado|                     47697|                      3.0|\n",
      "|             Acosta|                     15270|                      2.1|\n",
      "|              Tibas|                     52194|                      3.5|\n",
      "|            Moravia|                     45444|                      3.2|\n",
      "|      Montes de Oca|                     41561|                      2.9|\n",
      "|         Turrubares|                      4133|                      3.9|\n",
      "|               Dota|                      5164|                      1.8|\n",
      "|         Curridabat|                     51916|                      3.0|\n",
      "|      Perez Zeledon|                     98186|                      3.4|\n",
      "| Leon Cortes Castro|                      9084|                      2.4|\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "3- La cantidad de registros del INEC es: 82 \n",
      "\n",
      "\n",
      "2- Descripción general de los datos a utilizar: \n",
      "\n",
      "a-) El primer conjunto de datos contiene información tomada de las estadísticas policiales de la OIJ de Costa Rica.\n",
      "\n",
      "b-) Descripción de columnas para el conjunto de datos OIJ: \n",
      "\n",
      "Delito: Descripción del Delito\n",
      "SubDelito: Descripción del SubDelito\n",
      "Fecha: Fecha del Hecho\n",
      "Hora: Rango de 3 horas del Hecho\n",
      "Victima: Descripción de la Víctima \n",
      "SubVictima: Descripción de la SubVíctima\n",
      "Edad: Grupo de Edad que pertenece la Víctima\n",
      "Genero: Género de la Víctima\n",
      "Nacionalidad: Nacionalidad de la Víctima\n",
      "Provincia: Provincia del Lugar del Hecho\n",
      "Canton: Cantón del Lugar del Hecho\n",
      "Distrito: Distrito del Lugar del Hecho\n",
      "\n",
      "c-) El segundo conjunto de datos contiene información sobre indicadores económicos según la provincia, el cantón\n",
      "    y el distrito tomado del INEC.\n",
      "\n",
      "d-) Descripción de columnas para el conjunto de datos INEC: \n",
      "\n",
      "Columna 1: Provincia, Cantón y Distrito\n",
      "Columna 2: Población de 15 años y más\n",
      "Columna 3: Tasa neta de participación\n",
      "Columna 4: Tasa de ocupación\n",
      "Columna 5: Tasa de desempleo abierto\n",
      "Columna 6: Porcentaje de poblacion economicamente inactiva\n",
      "Columna 7: Relación de depedencia económica\n",
      "\n",
      "e-) La columna que se va a utilizar para predecir es la cantidad de delitos por cantón, delito, subdelito y hora.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def loading_initial_data(spark_session):\n",
    "    \"\"\"\n",
    "    This function loads initial data for INEC and OIJ before training model\n",
    "    \"\"\"\n",
    "    # Loading and cleaning OIJ CSV input file data.\n",
    "    oij_spark_df = load_oij_data(spark_session)\n",
    "    \n",
    "    # Show OIJ DataFrame\n",
    "    show_spark_dataframe(oij_spark_df,\n",
    "                         [\"Delito\", \"SubDelito\", \"Genero\", \"Canton\"])\n",
    "    \n",
    "    # Show OIJ DataFrame Rows count\n",
    "    print(\"\\n3- La cantidad de registros del OIJ es: %d \" % (oij_spark_df.count()))\n",
    "    \n",
    "    # Loading and cleaning INEC CSV input file data.\n",
    "    inec_spark_df = load_inec_data(spark_session)\n",
    "    \n",
    "    # Show Preprocessing INEC DataFrame\n",
    "    show_spark_dataframe(inec_spark_df,\n",
    "                         [\"Canton\",\n",
    "                          \"Poblacion de 15 anos y mas\",\n",
    "                          \"Tasa de desempleo abierto\"])\n",
    "    \n",
    "    # Show INEC DataFrame Rows count\n",
    "    print(\"\\n3- La cantidad de registros del INEC es: %d \\n\\n\" % (inec_spark_df.count()))\n",
    "    \n",
    "    return oij_spark_df, inec_spark_df\n",
    "\n",
    "def show_entry_data_description():\n",
    "    \"\"\"\n",
    "    This function shows a description of all the entry data columns\n",
    "    \"\"\"\n",
    "\n",
    "    # OIJ Dataset Explanation\n",
    "    print(\"\\na-) El primer conjunto de datos contiene información tomada de las estadísticas policiales de la OIJ de Costa Rica.\")\n",
    "    \n",
    "    print(\"\\nb-) Descripción de columnas para el conjunto de datos OIJ: \\n\")\n",
    "    print(\"Delito: Descripción del Delito\")\n",
    "    print(\"SubDelito: Descripción del SubDelito\")\n",
    "    print(\"Fecha: Fecha del Hecho\")\n",
    "    print(\"Hora: Rango de 3 horas del Hecho\")\n",
    "    print(\"Victima: Descripción de la Víctima \")\n",
    "    print(\"SubVictima: Descripción de la SubVíctima\")\n",
    "    print(\"Edad: Grupo de Edad que pertenece la Víctima\")\n",
    "    print(\"Genero: Género de la Víctima\")\n",
    "    print(\"Nacionalidad: Nacionalidad de la Víctima\")\n",
    "    print(\"Provincia: Provincia del Lugar del Hecho\")\n",
    "    print(\"Canton: Cantón del Lugar del Hecho\")\n",
    "    print(\"Distrito: Distrito del Lugar del Hecho\")\n",
    "    \n",
    "    # INEC Dataset Explanation\n",
    "    print(\"\\nc-) El segundo conjunto de datos contiene información sobre indicadores económicos según la provincia, el cantón\")\n",
    "    print(\"    y el distrito tomado del INEC.\")\n",
    "    \n",
    "    print(\"\\nd-) Descripción de columnas para el conjunto de datos INEC: \\n\")\n",
    "    print(\"Columna 1: Provincia, Cantón y Distrito\")\n",
    "    print(\"Columna 2: Población de 15 años y más\")\n",
    "    print(\"Columna 3: Tasa neta de participación\")\n",
    "    print(\"Columna 4: Tasa de ocupación\")\n",
    "    print(\"Columna 5: Tasa de desempleo abierto\")\n",
    "    print(\"Columna 6: Porcentaje de poblacion economicamente inactiva\")\n",
    "    print(\"Columna 7: Relación de depedencia económica\")\n",
    "    \n",
    "    # Show which columns is going to be predicted\n",
    "    print(\"\\ne-) La columna que se va a utilizar para predecir es la cantidad de delitos por cantón, delito, subdelito y hora.\\n\")\n",
    "\n",
    "# Step 1: Data Loading\n",
    "print(\"1- Carga inicial de los datos:\")\n",
    "spark_session = create_spark_session()\n",
    "oij_spark_df, inec_spark_df = loading_initial_data(spark_session)\n",
    "\n",
    "# Step 2: Data Description\n",
    "print(\"2- Descripción general de los datos a utilizar: \")\n",
    "show_entry_data_description()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNEzZTFDFL2R"
   },
   "source": [
    "## c) Exploración de los datos\n",
    "\n",
    "Dos variables clave para el análisis de delitos por zona geográficas son la “Tasa de ocupación” y la “Tasa de desempleo abierto”. A continuación, mostramos estadísticas generales para ambas variables sólo tomando en cuenta datos de la provincia de San José:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZX-MxwzFhF7"
   },
   "source": [
    "# **Código en Python para la exploración de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgCi5cMwFpEV"
   },
   "source": [
    "## Funciones encargadas de la exploración de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Exploración de los datos del OIJ: Cálculo de estadísticas para el DataFrame del OIJ\n",
      "- Exploración de los datos del INEC: Cálculo de estadísticas para el DataFrame del INEC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explore_oij_data(oij_spark_df):\n",
    "    # Convert the Spark DataFrame back to a pandas DataFrame using Arrow\n",
    "    oij_pandas_df = oij_spark_df.select(\"*\").toPandas()\n",
    "    \n",
    "    def show_crimes_histogram(oij_pdf):\n",
    "        # Shows a histogram of the number of crimes\n",
    "        plt.figure(1)\n",
    "        oij_pdf.Delito.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "        plt.title(\"Numero de delitos por tipo\")\n",
    "        plt.ylabel(\"Numero de delitos\")\n",
    "        plt.xlabel(\"Tipo de delitos\");\n",
    "        plt.show()\n",
    "    \n",
    "    # Shows OIJ Dat Histograms\n",
    "    show_crimes_histogram(oij_pandas_df)\n",
    "\n",
    "def explore_inec_data(inec_spark_df):\n",
    "    # Convert the Spark DataFrame back to a pandas DataFrame using Arrow\n",
    "    inec_pandas_df = inec_spark_df.select(\"*\").toPandas()\n",
    "    \n",
    "    def show_occupation_rate_scatter_plot(inec_pdf):\n",
    "        # Plotting a scatter plot\n",
    "        plt.figure(2)\n",
    "        plt.scatter(inec_pdf[\"Tasa de ocupacion\"], inec_pdf[\"Tasa de desempleo abierto\"])\n",
    "        plt.ylabel(\"Tasa de desempleo abierto\")\n",
    "        plt.xlabel(\"Tasa de ocupacion\");\n",
    "        plt.show()\n",
    "    \n",
    "    # Shows INEC Data Scatter Plot\n",
    "    show_occupation_rate_scatter_plot(inec_pandas_df)\n",
    "    \n",
    "\n",
    "# Step 4: Compute OIJ Statistics\n",
    "print(\"- Exploración de los datos del OIJ: Cálculo de estadísticas para el DataFrame del OIJ\")\n",
    "#explore_oij_data(oij_spark_df)\n",
    "\n",
    "#Step 5: Compute INEC Statistics\n",
    "print(\"- Exploración de los datos del INEC: Cálculo de estadísticas para el DataFrame del INEC\")\n",
    "explore_inec_data(inec_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Verificación de la calidad de datos\n",
    "\n",
    "El único problema de calidad que existe ocurre en el dataset que proviene del INEC. En este caso, el archivo viene en formato .xlsx, y una vez que se transforma a formato CSV ocurren problemas a la hora de parsear el archivo. Además, el nombre de los cantones viene diferente al del archivo del OIJ, por lo que es necesario estandarizar los nombres para que no haya ningún problema a la hora de unir los datos. Es importante resaltar que ambos archivos de datos no contiene datos faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III) Fase de preparación de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Código en Python para la selección de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selección de datos: \n",
      "\n",
      "- OIJ Dataset: Se remueven las columnas Fecha, SubVictima y Provincia. \n",
      "\n",
      "1-) Tipos de datos: \n",
      "\n",
      "root\n",
      " |-- Delito: string (nullable = true)\n",
      " |-- SubDelito: string (nullable = true)\n",
      " |-- Hora: string (nullable = true)\n",
      " |-- Victima: string (nullable = true)\n",
      " |-- Edad: string (nullable = true)\n",
      " |-- Genero: string (nullable = true)\n",
      " |-- Nacionalidad: string (nullable = true)\n",
      " |-- Canton: string (nullable = true)\n",
      "\n",
      "2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \n",
      "\n",
      "+------+-----------+------+-------------+\n",
      "|Delito|  SubDelito|Genero|       Canton|\n",
      "+------+-----------+------+-------------+\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   ALAJUELITA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     OREAMUNO|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|      HEREDIA|\n",
      "|ASALTO|ARMA BLANCA| MUJER|      HEREDIA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|      LIBERIA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     SAN JOSE|\n",
      "|ASALTO|ARMA BLANCA| MUJER|   GOICOECHEA|\n",
      "|ASALTO|ARMA BLANCA| MUJER|MONTES DE OCA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     SAN JOSE|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   CURRIDABAT|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|PEREZ ZELEDON|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|        LIMON|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|        LIMON|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|     SAN JOSE|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE| DESAMPARADOS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   PUNTARENAS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   PUNTARENAS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|       MATINA|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|   PUNTARENAS|\n",
      "|ASALTO|ARMA BLANCA|HOMBRE|      LIBERIA|\n",
      "+------+-----------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "- INEC Dataset: Se remueven las columnas Porcentaje de poblacion economicamente inactiva, \n",
      "Relacion de dependencia economica, Porcentaje de poblacion ocupada - Sector Primario, \n",
      "Porcentaje de poblacion ocupada - Sector Secundario, Porcentaje de poblacion ocupada - Sector Terciario\n",
      "\n",
      "1-) Tipos de datos: \n",
      "\n",
      "root\n",
      " |-- Canton: string (nullable = true)\n",
      " |-- Poblacion de 15 anos y mas: integer (nullable = true)\n",
      " |-- Tasa neta de participacion: float (nullable = true)\n",
      " |-- Tasa de ocupacion: float (nullable = true)\n",
      " |-- Tasa de desempleo abierto: float (nullable = true)\n",
      "\n",
      "2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \n",
      "\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "|             Canton|Poblacion de 15 anos y mas|Tasa de desempleo abierto|\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "|           San Jose|                    225856|                      3.9|\n",
      "|             Escazu|                     44797|                      3.0|\n",
      "|       Desamparados|                    159292|                      4.0|\n",
      "|           Puriscal|                     25774|                      3.1|\n",
      "|            Tarrazu|                     11800|                      2.8|\n",
      "|             Aserri|                     43396|                      3.2|\n",
      "|               Mora|                     20414|                      3.2|\n",
      "|         Goicoechea|                     90537|                      3.7|\n",
      "|          Santa Ana|                     38096|                      2.3|\n",
      "|         Alajuelita|                     56704|                      3.8|\n",
      "|Vazquez de Coronado|                     47697|                      3.0|\n",
      "|             Acosta|                     15270|                      2.1|\n",
      "|              Tibas|                     52194|                      3.5|\n",
      "|            Moravia|                     45444|                      3.2|\n",
      "|      Montes de Oca|                     41561|                      2.9|\n",
      "|         Turrubares|                      4133|                      3.9|\n",
      "|               Dota|                      5164|                      1.8|\n",
      "|         Curridabat|                     51916|                      3.0|\n",
      "|      Perez Zeledon|                     98186|                      3.4|\n",
      "| Leon Cortes Castro|                      9084|                      2.4|\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OIJ_DATAFRAME_UNNECESSARY_COLUMNS = [\"Fecha\", \"SubVictima\", \"Provincia\"]\n",
    "INEC_DATAFRAME_UNNECESSARY_COLUMNS = [\"Porcentaje de poblacion economicamente inactiva\",\n",
    "                                      \"Relacion de dependencia economica\",\n",
    "                                      \"Porcentaje de poblacion ocupada - Sector Primario\",\n",
    "                                      \"Porcentaje de poblacion ocupada - Sector Secundario\",\n",
    "                                      \"Porcentaje de poblacion ocupada - Sector Terciario\"]\n",
    "\n",
    "def remove_unnecessary_columns(spark_df, columns_to_remove_list):\n",
    "    \"\"\"\n",
    "    This function removes unnecessary columns for DataFrame\n",
    "    \"\"\"\n",
    "    columns_to_drop = columns_to_remove_list\n",
    "    spark_df = spark_df.drop(*columns_to_drop)\n",
    "    return spark_df\n",
    "\n",
    "def remove_oij_dataset_unnecessary_columns(oij_spark_df):\n",
    "    \"\"\"\n",
    "    This function selects data for the OIJ Dataset before training model\n",
    "    \"\"\"\n",
    "    oij_spark_df = remove_unnecessary_columns(oij_spark_df, OIJ_DATAFRAME_UNNECESSARY_COLUMNS)\n",
    "    \n",
    "    return oij_spark_df\n",
    "\n",
    "def remove_inec_dataset_unnecessary_columns(inec_spark_df):\n",
    "    \"\"\"\n",
    "    This function selects data for the INEC Dataset before training model\n",
    "    \"\"\"\n",
    "    inec_spark_df = remove_unnecessary_columns(inec_spark_df, INEC_DATAFRAME_UNNECESSARY_COLUMNS)\n",
    "    \n",
    "    return inec_spark_df\n",
    "\n",
    "# Step 5: Remove unnecessary data\n",
    "print(\"\\nSelección de datos: \\n\")\n",
    "print(\"- OIJ Dataset: Se remueven las columnas Fecha, SubVictima y Provincia. \")\n",
    "oij_spark_df = remove_oij_dataset_unnecessary_columns(oij_spark_df)\n",
    "show_spark_dataframe(oij_spark_df,\n",
    "                     [\"Delito\", \"SubDelito\", \"Genero\", \"Canton\"])\n",
    "\n",
    "print(\"- INEC Dataset: Se remueven las columnas \" + \"Porcentaje de poblacion economicamente inactiva, \\n\" +\n",
    "      \"Relacion de dependencia economica, \" + \"Porcentaje de poblacion ocupada - Sector Primario, \\n\" +\n",
    "      \"Porcentaje de poblacion ocupada - Sector Secundario, \" + \"Porcentaje de poblacion ocupada - Sector Terciario\")\n",
    "inec_spark_df = remove_inec_dataset_unnecessary_columns(inec_spark_df)\n",
    "show_spark_dataframe(inec_spark_df,\n",
    "                     [\"Canton\",\n",
    "                      \"Poblacion de 15 anos y mas\",\n",
    "                      \"Tasa de desempleo abierto\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Limpieza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Código en Python para la limpieza de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Limpieza de datos: \n",
      "\n",
      "- En ambos dataset se remueven los espacios en blanco y las columnas se convierten en minúsculas. \n",
      "\n",
      "- Limpieza del DataFrame: OIJ\n",
      "\n",
      "1-) Tipos de datos: \n",
      "\n",
      "root\n",
      " |-- Delito: string (nullable = true)\n",
      " |-- SubDelito: string (nullable = true)\n",
      " |-- Hora: string (nullable = true)\n",
      " |-- Victima: string (nullable = true)\n",
      " |-- Edad: string (nullable = true)\n",
      " |-- Genero: string (nullable = true)\n",
      " |-- Nacionalidad: string (nullable = true)\n",
      " |-- Canton: string (nullable = true)\n",
      "\n",
      "2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \n",
      "\n",
      "+------+-----------+------+-------------+\n",
      "|Delito|  SubDelito|Genero|       Canton|\n",
      "+------+-----------+------+-------------+\n",
      "|asalto|arma blanca|hombre|   alajuelita|\n",
      "|asalto|arma blanca|hombre|     oreamuno|\n",
      "|asalto|arma blanca|hombre|      heredia|\n",
      "|asalto|arma blanca| mujer|      heredia|\n",
      "|asalto|arma blanca|hombre|      liberia|\n",
      "|asalto|arma blanca|hombre|     san jose|\n",
      "|asalto|arma blanca| mujer|   goicoechea|\n",
      "|asalto|arma blanca| mujer|montes de oca|\n",
      "|asalto|arma blanca|hombre|     san jose|\n",
      "|asalto|arma blanca|hombre|   curridabat|\n",
      "|asalto|arma blanca|hombre|perez zeledon|\n",
      "|asalto|arma blanca|hombre|        limon|\n",
      "|asalto|arma blanca|hombre|        limon|\n",
      "|asalto|arma blanca|hombre|     san jose|\n",
      "|asalto|arma blanca|hombre| desamparados|\n",
      "|asalto|arma blanca|hombre|   puntarenas|\n",
      "|asalto|arma blanca|hombre|   puntarenas|\n",
      "|asalto|arma blanca|hombre|       matina|\n",
      "|asalto|arma blanca|hombre|   puntarenas|\n",
      "|asalto|arma blanca|hombre|      liberia|\n",
      "+------+-----------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "- Se demuestra que los datos se han convertido con éxito de tipo categórico a tipo numérico: \n",
      "\n",
      "+------+---------+----+-------+------+------------+\n",
      "|Delito|SubDelito|Hora|Victima|Genero|Nacionalidad|\n",
      "+------+---------+----+-------+------+------------+\n",
      "|   0.0|      5.0| 1.0|    0.0|   0.0|         1.0|\n",
      "|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 4.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 1.0|    0.0|   1.0|         0.0|\n",
      "|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 0.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 6.0|    0.0|   1.0|         0.0|\n",
      "|   0.0|      5.0| 1.0|    0.0|   1.0|         0.0|\n",
      "|   0.0|      5.0| 5.0|    4.0|   0.0|         2.0|\n",
      "|   0.0|      5.0| 4.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 0.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 6.0|    1.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 1.0|    0.0|   0.0|         1.0|\n",
      "|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 1.0|    0.0|   0.0|         1.0|\n",
      "|   0.0|      5.0| 5.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 2.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 5.0|    0.0|   0.0|         0.0|\n",
      "|   0.0|      5.0| 0.0|    0.0|   0.0|         0.0|\n",
      "+------+---------+----+-------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "- Limpieza del DataFrame: INEC\n",
      "\n",
      "1-) Tipos de datos: \n",
      "\n",
      "root\n",
      " |-- Canton: string (nullable = true)\n",
      " |-- Poblacion de 15 anos y mas: integer (nullable = true)\n",
      " |-- Tasa neta de participacion: float (nullable = true)\n",
      " |-- Tasa de ocupacion: float (nullable = true)\n",
      " |-- Tasa de desempleo abierto: float (nullable = true)\n",
      "\n",
      "2-) Se seleccionan las primeras filas para demostrar que los datos se han cargado con exito: \n",
      "\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "|             Canton|Poblacion de 15 anos y mas|Tasa de desempleo abierto|\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "|           san jose|                    225856|                      3.9|\n",
      "|             escazu|                     44797|                      3.0|\n",
      "|       desamparados|                    159292|                      4.0|\n",
      "|           puriscal|                     25774|                      3.1|\n",
      "|            tarrazu|                     11800|                      2.8|\n",
      "|             aserri|                     43396|                      3.2|\n",
      "|               mora|                     20414|                      3.2|\n",
      "|         goicoechea|                     90537|                      3.7|\n",
      "|          santa ana|                     38096|                      2.3|\n",
      "|         alajuelita|                     56704|                      3.8|\n",
      "|vazquez de coronado|                     47697|                      3.0|\n",
      "|             acosta|                     15270|                      2.1|\n",
      "|              tibas|                     52194|                      3.5|\n",
      "|            moravia|                     45444|                      3.2|\n",
      "|      montes de oca|                     41561|                      2.9|\n",
      "|         turrubares|                      4133|                      3.9|\n",
      "|               dota|                      5164|                      1.8|\n",
      "|         curridabat|                     51916|                      3.0|\n",
      "|      perez zeledon|                     98186|                      3.4|\n",
      "| leon cortes castro|                      9084|                      2.4|\n",
      "+-------------------+--------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_spark_dataframe_trailing_whitespaces(spark_df):\n",
    "    \"\"\"\n",
    "    This function removes all trailing whitespaces in Spark DataFrame Columns\n",
    "    spark_df: Spark DataFrame\n",
    "    return the Spark DataFrame\n",
    "    \"\"\"\n",
    "    for column in spark_df.columns:\n",
    "        spark_df = spark_df.withColumn(column, trim(col(column)).cast(spark_df.schema[column].dataType))\n",
    "    return spark_df\n",
    "\n",
    "def convert_spark_dataframe_to_lower_case(spark_df):\n",
    "    \"\"\"\n",
    "    This function converts to lower case Spark DataFrame Columns\n",
    "    spark_df: Spark DataFrame\n",
    "    columns_list: Columns List\n",
    "    return the Spark DataFrame\n",
    "    \"\"\"\n",
    "    for column in spark_df.columns:\n",
    "        spark_df =  spark_df.withColumn(column, lower(col(column)).cast(spark_df.schema[column].dataType))\n",
    "    return spark_df\n",
    "\n",
    "def clean_spark_dataframe(spark_df, dataframe_name):\n",
    "    \"\"\"\n",
    "    This function creates a Spark DataFrame from Dataset CSV file\n",
    "    spark_session: Spark Session\n",
    "    return the Spark DataFrame\n",
    "    \"\"\"\n",
    "    print(\"\\n- Limpieza del DataFrame: {name}\".format(name = dataframe_name))\n",
    "    \n",
    "    # Clean whitespaces\n",
    "    spark_df = remove_spark_dataframe_trailing_whitespaces(spark_df)\n",
    "    \n",
    "    # Convert to lower case\n",
    "    spark_df = convert_spark_dataframe_to_lower_case(spark_df)\n",
    "    \n",
    "    return spark_df\n",
    "\n",
    "# Step 6: Clean DataFrames\n",
    "print(\"\\nLimpieza de datos: \\n\")\n",
    "print(\"- En ambos dataset se remueven los espacios en blanco y las columnas se convierten en minúsculas. \")\n",
    "oij_spark_df = clean_spark_dataframe(oij_spark_df, \"OIJ\")\n",
    "show_spark_dataframe(oij_spark_df,\n",
    "                     [\"Delito\", \"SubDelito\", \"Genero\", \"Canton\"])\n",
    "\n",
    "# Convert all OIJ Categorical Values to Numerical Values, it has to change if columns change.\n",
    "oij_spark_df = convert_categorical_values_to_numerical_from_df(oij_spark_df,\n",
    "                                                               [\"Delito\", \"SubDelito\",\n",
    "                                                                \"Hora\",  \"Victima\", \"Genero\", \"Nacionalidad\"])\n",
    "\n",
    "inec_spark_df = clean_spark_dataframe(inec_spark_df, \"INEC\")\n",
    "show_spark_dataframe(inec_spark_df,\n",
    "                     [\"Canton\",\n",
    "                      \"Poblacion de 15 anos y mas\",\n",
    "                      \"Tasa de desempleo abierto\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Construcción de nuevos datos(atributos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Código en Python para la construcción de nuevos datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Escritura a la base de datos del dataset limpio y construcción de nuevos datos: \n",
      "\n",
      "\n",
      "- Antes de unir los datos, es importante escribir a la base de datos primero. \n",
      "\n",
      "- Después de escribir los datos del OIJ y el INEC en la base de datos, ahora se cargan limpios. \n",
      "\n",
      "- El conjunto de datos del OIJ: \n",
      "+-------------+-------------+------+---------+----+-------+------+------------+\n",
      "|         Edad|       Canton|Delito|SubDelito|Hora|Victima|Genero|Nacionalidad|\n",
      "+-------------+-------------+------+---------+----+-------+------+------------+\n",
      "|mayor de edad|   alajuelita|   0.0|      5.0| 1.0|    0.0|   0.0|         1.0|\n",
      "|mayor de edad|     oreamuno|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|      heredia|   0.0|      5.0| 4.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|      heredia|   0.0|      5.0| 1.0|    0.0|   1.0|         0.0|\n",
      "|mayor de edad|      liberia|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|     san jose|   0.0|      5.0| 0.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|   goicoechea|   0.0|      5.0| 6.0|    0.0|   1.0|         0.0|\n",
      "|mayor de edad|montes de oca|   0.0|      5.0| 1.0|    0.0|   1.0|         0.0|\n",
      "|menor de edad|     san jose|   0.0|      5.0| 5.0|    4.0|   0.0|         2.0|\n",
      "|mayor de edad|   curridabat|   0.0|      5.0| 4.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|perez zeledon|   0.0|      5.0| 0.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|        limon|   0.0|      5.0| 6.0|    1.0|   0.0|         0.0|\n",
      "|mayor de edad|        limon|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|     san jose|   0.0|      5.0| 1.0|    0.0|   0.0|         1.0|\n",
      "|mayor de edad| desamparados|   0.0|      5.0| 7.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|   puntarenas|   0.0|      5.0| 1.0|    0.0|   0.0|         1.0|\n",
      "|mayor de edad|   puntarenas|   0.0|      5.0| 5.0|    0.0|   0.0|         0.0|\n",
      "|menor de edad|       matina|   0.0|      5.0| 2.0|    0.0|   0.0|         0.0|\n",
      "|menor de edad|   puntarenas|   0.0|      5.0| 5.0|    0.0|   0.0|         0.0|\n",
      "|mayor de edad|      liberia|   0.0|      5.0| 0.0|    0.0|   0.0|         0.0|\n",
      "+-------------+-------------+------+---------+----+-------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "- El conjunto de datos del INEC: \n",
      "+-------------------+--------------------------+--------------------------+-----------------+-------------------------+\n",
      "|             Canton|Poblacion de 15 anos y mas|Tasa neta de participacion|Tasa de ocupacion|Tasa de desempleo abierto|\n",
      "+-------------------+--------------------------+--------------------------+-----------------+-------------------------+\n",
      "|           san jose|                    225856|                      56.7|             54.5|                      3.9|\n",
      "|             escazu|                     44797|                      60.7|             58.9|                      3.0|\n",
      "|       desamparados|                    159292|                      57.0|             54.7|                      4.0|\n",
      "|           puriscal|                     25774|                      50.7|             49.1|                      3.1|\n",
      "|            tarrazu|                     11800|                      51.2|             49.7|                      2.8|\n",
      "|             aserri|                     43396|                      54.5|             52.7|                      3.2|\n",
      "|               mora|                     20414|                      55.2|             53.4|                      3.2|\n",
      "|         goicoechea|                     90537|                      56.8|             54.7|                      3.7|\n",
      "|          santa ana|                     38096|                      61.8|             60.4|                      2.3|\n",
      "|         alajuelita|                     56704|                      56.0|             53.9|                      3.8|\n",
      "|vazquez de coronado|                     47697|                      58.4|             56.6|                      3.0|\n",
      "|             acosta|                     15270|                      49.6|             48.5|                      2.1|\n",
      "|              tibas|                     52194|                      56.0|             54.1|                      3.5|\n",
      "|            moravia|                     45444|                      58.7|             56.8|                      3.2|\n",
      "|      montes de oca|                     41561|                      58.8|             57.1|                      2.9|\n",
      "|         turrubares|                      4133|                      48.2|             46.3|                      3.9|\n",
      "|               dota|                      5164|                      51.2|             50.3|                      1.8|\n",
      "|         curridabat|                     51916|                      58.9|             57.1|                      3.0|\n",
      "|      perez zeledon|                     98186|                      48.0|             46.4|                      3.4|\n",
      "| leon cortes castro|                      9084|                      47.2|             46.0|                      2.4|\n",
      "+-------------------+--------------------------+--------------------------+-----------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Cuenta de delitos agrupados por las columnas Canton, Delito, SubDelito, Hora\n",
      "+-------------------+------+---------+----+-------+------+------------+-----+\n",
      "|             Canton|Delito|SubDelito|Hora|Victima|Genero|Nacionalidad|count|\n",
      "+-------------------+------+---------+----+-------+------+------------+-----+\n",
      "|       desamparados|   0.0|      5.0| 1.0|    0.0|   1.0|         0.0|    8|\n",
      "|           oreamuno|   0.0|      5.0| 1.0|    0.0|   0.0|         0.0|    5|\n",
      "|            heredia|   0.0|      5.0| 4.0|    1.0|   0.0|         0.0|    2|\n",
      "|           san jose|   0.0|      5.0| 4.0|    3.0|   0.0|         0.0|    2|\n",
      "|         goicoechea|   0.0|      1.0| 5.0|    0.0|   1.0|         1.0|    1|\n",
      "|            heredia|   0.0|      1.0| 1.0|    2.0|   1.0|         0.0|    1|\n",
      "|              tibas|   0.0|      1.0| 0.0|    0.0|   0.0|         1.0|    1|\n",
      "|           san jose|   0.0|      1.0| 0.0|    4.0|   0.0|         4.0|    1|\n",
      "|             escazu|   0.0|      1.0| 1.0|    1.0|   0.0|         1.0|    2|\n",
      "|vasquez de coronado|   0.0|      1.0| 5.0|    4.0|   0.0|         0.0|    1|\n",
      "|           san jose|   0.0|     21.0| 7.0|    0.0|   0.0|         1.0|    6|\n",
      "|      montes de oca|   0.0|      9.0| 1.0|    0.0|   1.0|         1.0|    1|\n",
      "|vasquez de coronado|   0.0|     19.0| 4.0|    0.0|   0.0|         0.0|    1|\n",
      "|         alajuelita|   0.0|     14.0| 4.0|    1.0|   0.0|         0.0|    2|\n",
      "|            naranjo|   0.0|     14.0| 1.0|    0.0|   0.0|         0.0|    1|\n",
      "|           san jose|   0.0|     19.0| 1.0|    1.0|   0.0|         0.0|    2|\n",
      "|            liberia|   0.0|      9.0| 6.0|    1.0|   0.0|         0.0|    1|\n",
      "|       desamparados|   0.0|     14.0| 2.0|    0.0|   0.0|         2.0|    1|\n",
      "|            heredia|   2.0|     13.0| 1.0|    3.0|   0.0|         0.0|    1|\n",
      "|              tibas|   2.0|     13.0| 0.0|    3.0|   0.0|         0.0|    2|\n",
      "+-------------------+------+---------+----+-------+------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def write_and_read_oij_and_inec_df(spark_session, oij_spark_df, inec_spark_df):\n",
    "    \"\"\"\n",
    "    This function write and read OIJ and INEC DF to DB\n",
    "    \"\"\"\n",
    "    # Writing OIJ and INEC Dataframes to DB first\n",
    "    print(\"\\n- Antes de unir los datos, es importante escribir a la base de datos primero. \")\n",
    "    write_spark_df_to_db(oij_spark_df, \"oij\")\n",
    "    write_spark_df_to_db(inec_spark_df, \"inec\")\n",
    "    \n",
    "    # Reading OIJ and INEC Dataframes from DB\n",
    "    print(\"\\n- Después de escribir los datos del OIJ y el INEC en la base de datos, ahora se cargan limpios. \")\n",
    "    print(\"\\n- El conjunto de datos del OIJ: \")\n",
    "    read_dataset_from_db(spark_session, \"oij\")\n",
    "    print(\"\\n- El conjunto de datos del INEC: \")\n",
    "    read_dataset_from_db(spark_session, \"inec\")\n",
    "    \n",
    "    return oij_spark_df, inec_spark_df\n",
    "\n",
    "def add_new_attributes(spark_session, oij_spark_df, inec_spark_df):\n",
    "    \"\"\"\n",
    "    This function materialize data to write to DB\n",
    "    \"\"\"\n",
    "    # Writing and Reading OIJ and INEC Dataframes\n",
    "    oij_spark_df, inec_spark_df = write_and_read_oij_and_inec_df(spark_session,\n",
    "                                                                 oij_spark_df, inec_spark_df)\n",
    " \n",
    "    # Count Delito,SubDelito, Hora \n",
    "    oij_spark_df = count_delitos(spark_session, oij_spark_df)\n",
    "    \n",
    "    return oij_spark_df, inec_spark_df\n",
    "\n",
    "# Step 7: Add Count attribute\n",
    "print(\"\\n- Escritura a la base de datos del dataset limpio y construcción de nuevos datos: \\n\")\n",
    "oij_spark_df, inec_spark_df = add_new_attributes(spark_session, oij_spark_df, inec_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Transformaciones aplicadas a los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Código en Python para transformaciones a datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Transformación de los datos: \n",
      "\n",
      "\n",
      "La unión de datos entre los data frame del OIJ y del INEC es la siguiente: \n",
      "\n",
      "Data frame totalizado\n",
      "+------+---------+----+-------+------+------------+-----+-------------+--------------------------+--------------------------+-----------------+-------------------------+\n",
      "|Delito|SubDelito|Hora|Victima|Genero|Nacionalidad|count|       Canton|Poblacion de 15 anos y mas|Tasa neta de participacion|Tasa de ocupacion|Tasa de desempleo abierto|\n",
      "+------+---------+----+-------+------+------------+-----+-------------+--------------------------+--------------------------+-----------------+-------------------------+\n",
      "|   0.0|      5.0| 1.0|    0.0|   1.0|         0.0|    8| desamparados|                    159292|                      57.0|             54.7|                      4.0|\n",
      "|   0.0|      5.0| 1.0|    0.0|   0.0|         0.0|    5|     oreamuno|                     34110|                      53.9|             52.4|                      2.8|\n",
      "|   0.0|      5.0| 4.0|    1.0|   0.0|         0.0|    2|      heredia|                     96888|                      58.9|             57.0|                      3.2|\n",
      "|   0.0|      5.0| 4.0|    3.0|   0.0|         0.0|    2|     san jose|                    225856|                      56.7|             54.5|                      3.9|\n",
      "|   0.0|      1.0| 5.0|    0.0|   1.0|         1.0|    1|   goicoechea|                     90537|                      56.8|             54.7|                      3.7|\n",
      "|   0.0|      1.0| 1.0|    2.0|   1.0|         0.0|    1|      heredia|                     96888|                      58.9|             57.0|                      3.2|\n",
      "|   0.0|      1.0| 0.0|    0.0|   0.0|         1.0|    1|        tibas|                     52194|                      56.0|             54.1|                      3.5|\n",
      "|   0.0|      1.0| 0.0|    4.0|   0.0|         4.0|    1|     san jose|                    225856|                      56.7|             54.5|                      3.9|\n",
      "|   0.0|      1.0| 1.0|    1.0|   0.0|         1.0|    2|       escazu|                     44797|                      60.7|             58.9|                      3.0|\n",
      "|   0.0|     21.0| 7.0|    0.0|   0.0|         1.0|    6|     san jose|                    225856|                      56.7|             54.5|                      3.9|\n",
      "|   0.0|      9.0| 1.0|    0.0|   1.0|         1.0|    1|montes de oca|                     41561|                      58.8|             57.1|                      2.9|\n",
      "|   0.0|     14.0| 4.0|    1.0|   0.0|         0.0|    2|   alajuelita|                     56704|                      56.0|             53.9|                      3.8|\n",
      "|   0.0|     14.0| 1.0|    0.0|   0.0|         0.0|    1|      naranjo|                     32302|                      50.7|             49.3|                      2.7|\n",
      "|   0.0|     19.0| 1.0|    1.0|   0.0|         0.0|    2|     san jose|                    225856|                      56.7|             54.5|                      3.9|\n",
      "|   0.0|      9.0| 6.0|    1.0|   0.0|         0.0|    1|      liberia|                     45580|                      52.1|             49.5|                      4.8|\n",
      "|   0.0|     14.0| 2.0|    0.0|   0.0|         2.0|    1| desamparados|                    159292|                      57.0|             54.7|                      4.0|\n",
      "|   2.0|     13.0| 1.0|    3.0|   0.0|         0.0|    1|      heredia|                     96888|                      58.9|             57.0|                      3.2|\n",
      "|   2.0|     13.0| 0.0|    3.0|   0.0|         0.0|    2|        tibas|                     52194|                      56.0|             54.1|                      3.5|\n",
      "|   2.0|     15.0| 1.0|    0.0|   0.0|        26.0|    1|   goicoechea|                     90537|                      56.8|             54.7|                      3.7|\n",
      "|   2.0|      6.0| 0.0|    3.0|   1.0|         0.0|    3|       pococi|                     89730|                      51.2|             48.9|                      4.5|\n",
      "+------+---------+----+-------+------+------------+-----+-------------+--------------------------+--------------------------+-----------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "+------+---------+----+-------------+--------------------------+-------------------------+-----------------+\n",
      "|Delito|SubDelito|Hora|       Canton|Poblacion de 15 anos y mas|Tasa de desempleo abierto|Tasa de ocupacion|\n",
      "+------+---------+----+-------------+--------------------------+-------------------------+-----------------+\n",
      "|   0.0|      5.0| 1.0| desamparados|                    159292|                      4.0|             54.7|\n",
      "|   0.0|      5.0| 1.0|     oreamuno|                     34110|                      2.8|             52.4|\n",
      "|   0.0|      5.0| 4.0|      heredia|                     96888|                      3.2|             57.0|\n",
      "|   0.0|      5.0| 4.0|     san jose|                    225856|                      3.9|             54.5|\n",
      "|   0.0|      1.0| 5.0|   goicoechea|                     90537|                      3.7|             54.7|\n",
      "|   0.0|      1.0| 1.0|      heredia|                     96888|                      3.2|             57.0|\n",
      "|   0.0|      1.0| 0.0|        tibas|                     52194|                      3.5|             54.1|\n",
      "|   0.0|      1.0| 0.0|     san jose|                    225856|                      3.9|             54.5|\n",
      "|   0.0|      1.0| 1.0|       escazu|                     44797|                      3.0|             58.9|\n",
      "|   0.0|     21.0| 7.0|     san jose|                    225856|                      3.9|             54.5|\n",
      "|   0.0|      9.0| 1.0|montes de oca|                     41561|                      2.9|             57.1|\n",
      "|   0.0|     14.0| 4.0|   alajuelita|                     56704|                      3.8|             53.9|\n",
      "|   0.0|     14.0| 1.0|      naranjo|                     32302|                      2.7|             49.3|\n",
      "|   0.0|     19.0| 1.0|     san jose|                    225856|                      3.9|             54.5|\n",
      "|   0.0|      9.0| 6.0|      liberia|                     45580|                      4.8|             49.5|\n",
      "|   0.0|     14.0| 2.0| desamparados|                    159292|                      4.0|             54.7|\n",
      "|   2.0|     13.0| 1.0|      heredia|                     96888|                      3.2|             57.0|\n",
      "|   2.0|     13.0| 0.0|        tibas|                     52194|                      3.5|             54.1|\n",
      "|   2.0|     15.0| 1.0|   goicoechea|                     90537|                      3.7|             54.7|\n",
      "|   2.0|      6.0| 0.0|       pococi|                     89730|                      4.5|             48.9|\n",
      "+------+---------+----+-------------+--------------------------+-------------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "- Se demuestra que los datos se han convertido con éxito de tipo categórico a tipo numérico: \n",
      "\n",
      "+------+\n",
      "|Canton|\n",
      "+------+\n",
      "|   3.0|\n",
      "|  46.0|\n",
      "|  10.0|\n",
      "|   0.0|\n",
      "|   9.0|\n",
      "|  10.0|\n",
      "|  17.0|\n",
      "|   0.0|\n",
      "|  14.0|\n",
      "|   0.0|\n",
      "|   6.0|\n",
      "|  23.0|\n",
      "|  56.0|\n",
      "|   0.0|\n",
      "|   5.0|\n",
      "|   3.0|\n",
      "|  10.0|\n",
      "|  17.0|\n",
      "|   9.0|\n",
      "|  12.0|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "- After normalizing the data, the DataFrame looks like this: \n",
      "\n",
      "+-----+--------------------+--------------------+\n",
      "|count|            features|     scaled_features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    8|[5.0,1.0,0.0,0.0,...|[0.78267143811357...|\n",
      "|    5|[5.0,1.0,0.0,0.0,...|[0.78267143811357...|\n",
      "|    2|[5.0,4.0,0.0,1.0,...|[0.78267143811357...|\n",
      "|    2|[5.0,4.0,0.0,3.0,...|[0.78267143811357...|\n",
      "|    1|[1.0,5.0,0.0,0.0,...|[0.15653428762271...|\n",
      "|    1|[1.0,1.0,0.0,2.0,...|[0.15653428762271...|\n",
      "|    1|[1.0,0.0,0.0,0.0,...|[0.15653428762271...|\n",
      "|    1|[1.0,0.0,0.0,4.0,...|[0.15653428762271...|\n",
      "|    2|[1.0,1.0,0.0,1.0,...|[0.15653428762271...|\n",
      "|    6|[21.0,7.0,0.0,0.0...|[3.28722004007701...|\n",
      "|    1|[9.0,1.0,0.0,0.0,...|[1.40880858860443...|\n",
      "|    2|[14.0,4.0,0.0,1.0...|[2.19148002671800...|\n",
      "|    1|[14.0,1.0,0.0,0.0...|[2.19148002671800...|\n",
      "|    2|[19.0,1.0,0.0,1.0...|[2.97415146483158...|\n",
      "|    1|[9.0,6.0,0.0,1.0,...|[1.40880858860443...|\n",
      "|    1|[14.0,2.0,0.0,0.0...|[2.19148002671800...|\n",
      "|    1|[13.0,1.0,2.0,3.0...|[2.03494573909529...|\n",
      "|    2|[13.0,0.0,2.0,3.0...|[2.03494573909529...|\n",
      "|    1|[15.0,1.0,2.0,0.0...|[2.34801431434072...|\n",
      "|    3|[6.0,0.0,2.0,3.0,...|[0.93920572573628...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "g-) Escribiendo en la base de datos: \n",
      "\n",
      "g.1-) Antes de escribir el Dataframe normalizado, es necesario convertirlo en una tabla válida de la DB: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Después de convertirlo en una tabla válida en la DB, el DataFrame se ve así: \n",
      "\n",
      "+-------------------+-------------------+------------------+-----------------+------------------+-------------------+--------------------------+\n",
      "|          SubDelito|               Hora|            Delito|          Victima|            Genero|       Nacionalidad|Poblacion de 15 anos y mas|\n",
      "+-------------------+-------------------+------------------+-----------------+------------------+-------------------+--------------------------+\n",
      "| 0.7826714381135748|0.44571708454502584|               0.0|              0.0|1.9790107764423923|                0.0|        2.4210597222435912|\n",
      "| 0.7826714381135748|0.44571708454502584|               0.0|              0.0|               0.0|                0.0|        0.5184337388301289|\n",
      "| 0.7826714381135748| 1.7828683381801034|               0.0|0.762478730867025|               0.0|                0.0|        1.4725889207790541|\n",
      "| 0.7826714381135748| 1.7828683381801034|               0.0|2.287436192601075|               0.0|                0.0|        3.4327578574382174|\n",
      "|0.15653428762271496| 2.2285854227251294|               0.0|              0.0|1.9790107764423923|0.14464976084766842|        1.3760608446925648|\n",
      "|0.15653428762271496|0.44571708454502584|               0.0| 1.52495746173405|1.9790107764423923|                0.0|        1.4725889207790541|\n",
      "|0.15653428762271496|                0.0|               0.0|              0.0|               0.0|0.14464976084766842|        0.7932902540164102|\n",
      "|0.15653428762271496|                0.0|               0.0|  3.0499149234681|               0.0| 0.5785990433906737|        3.4327578574382174|\n",
      "|0.15653428762271496|0.44571708454502584|               0.0|0.762478730867025|               0.0|0.14464976084766842|        0.6808641512275956|\n",
      "|  3.287220040077014|  3.120019591815181|               0.0|              0.0|               0.0|0.14464976084766842|        3.4327578574382174|\n",
      "| 1.4088085886044346|0.44571708454502584|               0.0|              0.0|1.9790107764423923|0.14464976084766842|        0.6316805810471706|\n",
      "| 2.1914800267180095| 1.7828683381801034|               0.0|0.762478730867025|               0.0|                0.0|        0.8618371951516749|\n",
      "| 2.1914800267180095|0.44571708454502584|               0.0|              0.0|               0.0|                0.0|         0.490954166862821|\n",
      "| 2.9741514648315843|0.44571708454502584|               0.0|0.762478730867025|               0.0|                0.0|        3.4327578574382174|\n",
      "| 1.4088085886044346|  2.674302507270155|               0.0|0.762478730867025|               0.0|                0.0|        0.6927648729368888|\n",
      "| 2.1914800267180095| 0.8914341690900517|               0.0|              0.0|               0.0|0.28929952169533685|        2.4210597222435912|\n",
      "| 2.0349457390952943|0.44571708454502584|1.7028118329010138|2.287436192601075|               0.0|                0.0|        1.4725889207790541|\n",
      "| 2.0349457390952943|                0.0|1.7028118329010138|2.287436192601075|               0.0|                0.0|        0.7932902540164102|\n",
      "|  2.348014314340724|0.44571708454502584|1.7028118329010138|              0.0|               0.0|  3.760893782039379|        1.3760608446925648|\n",
      "| 0.9392057257362898|                0.0|1.7028118329010138|2.287436192601075|1.9790107764423923|                0.0|        1.3637953499040596|\n",
      "+-------------------+-------------------+------------------+-----------------+------------------+-------------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "- Para verificar que esta tabla fue escrita correctamente en DB,\n",
      "  se debe verificar en PostgreSQL la tabla llamada datos_cruzados.\n"
     ]
    }
   ],
   "source": [
    "FEATURES_LIST = ['SubDelito', 'Hora', 'Delito',  \"Victima\", \"Genero\", \"Nacionalidad\",\n",
    "                 'Poblacion de 15 anos y mas', 'Tasa neta de participacion',\n",
    "                 'Tasa de ocupacion', 'Tasa de desempleo abierto', 'Canton', 'count']\n",
    "\n",
    "def create_joint_spark_data_frames(oij_data_frame, inec_data_frame):\n",
    "    \"\"\"\n",
    "    This function creates the data frame of the joint of the two datasets\n",
    "    oij_data_frame: DataFrame with the students info\n",
    "    inec_data_frame: DataFrame with the courses info\n",
    "    return the joint Spark DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nLa unión de datos entre los data frame del OIJ y del INEC es la siguiente: \\n\")\n",
    "    joint_oij_and_inec_df = join_spark_data_frames(oij_data_frame,\n",
    "                                                   inec_data_frame,\n",
    "                                                   oij_data_frame.Canton,\n",
    "                                                   inec_data_frame.Canton)\n",
    "    \n",
    "    print(\"Data frame totalizado\")\n",
    "    print(joint_oij_and_inec_df.show())\n",
    "        \n",
    "    joint_oij_and_inec_df.select([\"Delito\", \"SubDelito\", \"Hora\", \"Canton\",\n",
    "                                  \"Poblacion de 15 anos y mas\",\n",
    "                                  \"Tasa de desempleo abierto\",\n",
    "                                  \"Tasa de ocupacion\"]).show(20)\n",
    "\n",
    "    return joint_oij_and_inec_df\n",
    "\n",
    "def transform_sparse_vector_df_to_dense_vector_df(spark_df):\n",
    "    \"\"\"\n",
    "    This function transforms a sparse vector to a dense vector df\n",
    "    \"\"\"\n",
    "    toDense = lambda v: Vectors.dense(v.toArray())\n",
    "    toDenseUdf = udf(toDense, VectorUDT())\n",
    "    spark_df = spark_df.withColumn('features', toDenseUdf('features'))\n",
    "    return spark_df\n",
    "\n",
    "def transform_spark_df_to_features_vector_df(spark_df, remove_delito=False):\n",
    "    \"\"\"\n",
    "    This function transforms a spark df to a features vector df\n",
    "    \"\"\"\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=FEATURES_LIST[:-1] if remove_delito else \\\n",
    "                  FEATURES_LIST,\n",
    "        outputCol='features')\n",
    "    \n",
    "    vector_df = assembler.transform(spark_df)\n",
    "    #vector_df = vector_df.select(['features', 'Delito'])\n",
    "    \n",
    "    # Converte Sparse Vectors to Dense Vectors\n",
    "    vector_df = transform_sparse_vector_df_to_dense_vector_df(vector_df)\n",
    "\n",
    "    return vector_df\n",
    "\n",
    "def normalize_data(spark_df):\n",
    "    \"\"\"\n",
    "    This function normalize data before training the model\n",
    "    \"\"\"\n",
    "    vector_df = transform_spark_df_to_features_vector_df(spark_df, remove_delito=True)\n",
    "    standard_scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "    scale_model = standard_scaler.fit(vector_df)\n",
    "    scaled_df = scale_model.transform(vector_df)\n",
    "    \n",
    "    return scaled_df\n",
    "\n",
    "def convert_normalized_df_to_valid_table_for_db(normalized_df):\n",
    "    \"\"\"\n",
    "    This function converts normalize features vector into a valid DF for DB\n",
    "    \"\"\"\n",
    "    normalized_valid_db_format_df = normalized_df.select('scaled_features', 'count')\n",
    "    normalized_lambda_function = lambda x:[float(y) for y in x['scaled_features']]+[x['count']]\n",
    "    normalized_valid_db_format_df = normalized_valid_db_format_df.rdd.map(normalized_lambda_function).toDF(FEATURES_LIST)\n",
    "    \n",
    "    return normalized_valid_db_format_df\n",
    "\n",
    "def transform_data(oij_spark_df, inec_spark_df):\n",
    "    # Joint Spark Data Frames\n",
    "    joint_data_frame = create_joint_spark_data_frames(oij_spark_df,\n",
    "                                                      inec_spark_df)\n",
    "        \n",
    "    # Convert Canton Categorical Value to Numerical Values\n",
    "    joint_data_frame = convert_categorical_values_to_numerical_from_df(joint_data_frame,\n",
    "                                                                       [\"Canton\"])\n",
    "    # Normalizing the data\n",
    "    print(\"\\n- After normalizing the data, the DataFrame looks like this: \\n\")\n",
    "    normalized_df = normalize_data(joint_data_frame)\n",
    "    normalized_df.select(\"count\", \"features\", \"scaled_features\").show()\n",
    "        \n",
    "    # Convert to valid format for DB\n",
    "    print(\"\\ng-) Escribiendo en la base de datos: \")\n",
    "    print(\"\\ng.1-) Antes de escribir el Dataframe normalizado, es necesario convertirlo en una tabla válida de la DB: \")\n",
    "    normalized_valid_db_df = convert_normalized_df_to_valid_table_for_db(normalized_df)\n",
    "    print(\"- Después de convertirlo en una tabla válida en la DB, el DataFrame se ve así: \\n\")\n",
    "    normalized_valid_db_df.select(FEATURES_LIST[:-5]).show()\n",
    "        \n",
    "    # Writing to DB\n",
    "    write_spark_df_to_db(normalized_valid_db_df, \"datos_cruzados\")\n",
    "    print(\"- Para verificar que esta tabla fue escrita correctamente en DB,\")\n",
    "    print(\"  se debe verificar en PostgreSQL la tabla llamada datos_cruzados.\")\n",
    "\n",
    "    return joint_data_frame\n",
    "\n",
    "# Step 8: Transform Data\n",
    "print(\"\\n- Transformación de los datos: \\n\")\n",
    "joint_spark_df = transform_data(oij_spark_df, inec_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bK0HCl1W42PH"
   },
   "source": [
    "# **IV) Fase de modelado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Selección de las técnicas a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HqWMRdS42PI",
    "outputId": "61367d75-d089-46c5-876d-6ec82b4b94c3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models\n",
      "\n",
      "- Leyendo de la DB:\n",
      "+-------------------+-------------------+------+-----------------+------------------+-------------------+--------------------------+--------------------------+------------------+-------------------------+-------------------+-----+\n",
      "|          SubDelito|               Hora|Delito|          Victima|            Genero|       Nacionalidad|Poblacion de 15 anos y mas|Tasa neta de participacion| Tasa de ocupacion|Tasa de desempleo abierto|             Canton|count|\n",
      "+-------------------+-------------------+------+-----------------+------------------+-------------------+--------------------------+--------------------------+------------------+-------------------------+-------------------+-----+\n",
      "| 0.7826714381135748|  2.674302507270155|   0.0|              0.0|1.9790107764423923|                0.0|        0.6906978254880205|         12.63687270897466|12.389210842746637|        4.580647763824036| 1.4135790654969127|    1|\n",
      "|0.15653428762271496| 0.8914341690900517|   0.0|2.287436192601075|               0.0|                0.0|        0.7890649658488705|        12.679928657017498|12.454646649974274|       4.2943572145941245| 0.6806121426466616|    2|\n",
      "| 0.7826714381135748| 0.8914341690900517|   0.0|              0.0|1.9790107764423923|                0.0|        0.5870566743568962|         9.407688924120347| 9.182847967978079|         5.15322852099901| 1.0994503842753764|    1|\n",
      "|0.15653428762271496| 1.7828683381801034|   0.0|              0.0|               0.0|                0.0|         1.140356640008377|        12.766039731879271|12.498270798813177|        4.866938313053947| 0.8376764832574297|   16|\n",
      "|0.15653428762271496| 0.8914341690900517|   0.0|2.287436192601075|               0.0| 1.4464976084766843|        0.6105997368443741|        10.893112972418988|   10.644251545682|         5.15322852099901| 0.9423860436646084|    1|\n",
      "| 0.7826714381135748| 2.2285854227251294|   0.0|              0.0|               0.0|0.14464976084766842|        3.4327578574382174|        12.206314870994085|11.887535211252839|        5.582664515486301|                0.0|    3|\n",
      "|0.15653428762271496| 2.2285854227251294|   0.0|0.762478730867025|               0.0|                0.0|         2.963826865232824|        12.012563515413266|11.756663596797566|        5.010083417026479|0.05235478020358936|    2|\n",
      "| 0.7826714381135748| 1.3371512536350776|   0.0|              0.0|               0.0|                0.0|        1.7754721675514613|        11.668117573518366|11.494919535825582|        4.008066665364213|0.41883824162871486|    1|\n",
      "|0.15653428762271496| 2.2285854227251294|   0.0|              0.0|1.9790107764423923|                0.0|        0.8843011372798171|         11.58200567743269|11.385859579759043|        4.151212110621593| 1.5706434061076808|    1|\n",
      "|0.15653428762271496| 1.7828683381801034|   0.0|  3.0499149234681|               0.0|                0.0|        0.7890649658488705|        12.679928657017498|12.454646649974274|       4.2943572145941245| 0.6806121426466616|    3|\n",
      "| 0.7826714381135748|  2.674302507270155|   0.0|              0.0|               0.0|                0.0|        0.4108560782191746|        11.129920276042647|10.927807265042716|        4.580647763824036|  2.513029449772289|    1|\n",
      "|0.15653428762271496| 1.7828683381801034|   0.0|              0.0|               0.0|                0.0|        0.6927648729368888|        11.216031350904421|10.796935650587441|        6.870971816378478| 0.2617739010179468|    6|\n",
      "|0.15653428762271496|                0.0|   0.0|0.762478730867025|               0.0|                0.0|        0.8008288976534592|        10.225748652038659|10.055327616510398|       4.2943572145941245| 1.2565147248861446|    1|\n",
      "| 1.4088085886044346| 2.2285854227251294|   0.0|              0.0|               0.0| 0.8678985650860105|        1.3637953499040596|        11.022280816547504|10.666064036132166|        6.441535821891186| 0.6282573624430723|    1|\n",
      "|0.15653428762271496|0.44571708454502584|   0.0|              0.0|               0.0|0.14464976084766842|        2.4210597222435912|        12.270898382446392|11.931159360091742|        5.725809619458833|0.15706434061076807|   11|\n",
      "|0.15653428762271496|0.44571708454502584|   0.0|              0.0|1.9790107764423923| 2.8929952169533686|        0.3040687592798464|         10.91464135705236|10.840559799426345|        3.006049913701948| 2.6700937903830573|    1|\n",
      "| 1.4088085886044346|                0.0|   0.0|              0.0|1.9790107764423923|                0.0|        3.4327578574382174|        12.206314870994085|11.887535211252839|        5.582664515486301|                0.0|    5|\n",
      "| 1.4088085886044346| 0.8914341690900517|   0.0|              0.0|1.9790107764423923|0.14464976084766842|        0.7890649658488705|        12.679928657017498|12.454646649974274|       4.2943572145941245| 0.6806121426466616|    1|\n",
      "|0.15653428762271496| 2.2285854227251294|   0.0|  3.0499149234681|               0.0|                0.0|        1.3760608446925648|        12.227842434403552|11.931159360091742|         5.29637396625639| 0.4711930218323042|    3|\n",
      "|  4.382960053436019|0.44571708454502584|   0.0|              0.0|               0.0|                0.0|         1.140356640008377|        12.766039731879271|12.498270798813177|        4.866938313053947| 0.8376764832574297|    1|\n",
      "+-------------------+-------------------+------+-----------------+------------------+-------------------+--------------------------+--------------------------+------------------+-------------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "- Condificando las características en un solo vector:\n",
      "+-----+--------------------+\n",
      "|count|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[0.78267143811357...|\n",
      "|    2|[0.15653428762271...|\n",
      "|    1|[0.78267143811357...|\n",
      "|   16|[0.15653428762271...|\n",
      "|    1|[0.15653428762271...|\n",
      "|    3|[0.78267143811357...|\n",
      "|    2|[0.15653428762271...|\n",
      "|    1|[0.78267143811357...|\n",
      "|    1|[0.15653428762271...|\n",
      "|    3|[0.15653428762271...|\n",
      "|    1|[0.78267143811357...|\n",
      "|    6|[0.15653428762271...|\n",
      "|    1|[0.15653428762271...|\n",
      "|    1|[1.40880858860443...|\n",
      "|   11|[0.15653428762271...|\n",
      "|    1|[0.15653428762271...|\n",
      "|    5|(9,[0,4,6,7],[1.4...|\n",
      "|    1|[1.40880858860443...|\n",
      "|    3|[0.15653428762271...|\n",
      "|    1|[4.38296005343601...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "OJOJOJOO que tiene el train_data\n",
      "+---------+----+------------------+-------+------------------+-------------------+--------------------------+--------------------------+------------------+-------------------------+-------------------+-----+--------------------+\n",
      "|SubDelito|Hora|            Delito|Victima|            Genero|       Nacionalidad|Poblacion de 15 anos y mas|Tasa neta de participacion| Tasa de ocupacion|Tasa de desempleo abierto|             Canton|count|            features|\n",
      "+---------+----+------------------+-------+------------------+-------------------+--------------------------+--------------------------+------------------+-------------------------+-------------------+-----+--------------------+\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|       0.16981706725151072|        10.139636755952983|  9.98989180928276|        4.008066665364213|  3.560125053844076|    3|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        0.2461458340766326|        10.225748652038659| 9.968080150894025|        5.439519070228921| 2.8271581309938254|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|       0.28917385854535427|         10.72089000147154|10.513379931226725|        4.580647763824036| 1.5182886259040913|    4|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|       0.46596721093679544|         9.730607302605778| 9.531840326627867|        4.866938313053947| 2.0941912081435743|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        0.4756032997793138|        11.861868107875283|11.625791150280858|       4.7237928677965675|  2.198900768550753|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        0.8008288976534592|        10.225748652038659|10.055327616510398|       4.2943572145941245| 1.2565147248861446|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        0.9284082821078744|        10.979224868504666|10.796935650587441|        4.151212110621593| 1.0470956040717871|    2|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        1.4725889207790541|        12.679928657017498|12.432834991585539|        4.580647763824036| 0.5235478020358936|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        1.4923170648131059|        10.333388111533804|10.120764255799468|        4.866938313053947|  0.575902582239483|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        1.7322465576648332|         11.45283865452808|11.211363816464866|       4.7237928677965675| 0.7853217030538404|    2|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|        1.7754721675514613|        11.668117573518366|11.494919535825582|        4.008066665364213|0.41883824162871486|    4|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|                0.0|         2.963826865232824|        12.012563515413266|11.756663596797566|        5.010083417026479|0.05235478020358936|    1|(9,[2,6,7,8],[0.8...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|0.14464976084766842|        0.5870566743568962|         9.407688924120347| 9.182847967978079|         5.15322852099901| 1.0994503842753764|    1|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0|0.28929952169533685|       0.30244247930169266|        10.850057845600054|10.666064036132166|        4.151212110621593| 1.3612242852933232|    1|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|               0.0| 1.5911473693243527|       0.21334665470414893|          9.88130271014376| 9.619087792244239|        5.439519070228921|  2.774803350790236|    1|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|1.9790107764423923|                0.0|       0.08391300709707247|         9.429216487529814| 9.335532072883522|        3.149195358959328| 3.7695441746584337|    1|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|1.9790107764423923|                0.0|       0.22349950540888439|        10.462555134438414|10.295260019093645|        4.151212110621593|  3.088932032011772|    1|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|1.9790107764423923|                0.0|       0.46596721093679544|         9.730607302605778| 9.531840326627867|        4.866938313053947| 2.0941912081435743|    2|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|1.9790107764423923|                0.0|        1.7322465576648332|         11.45283865452808|11.211363816464866|       4.7237928677965675| 0.7853217030538404|    1|[0.0,0.0,0.851405...|\n",
      "|      0.0| 0.0|0.8514059164505069|    0.0|1.9790107764423923|                0.0|         2.963826865232824|        12.012563515413266|11.756663596797566|        5.010083417026479|0.05235478020358936|    1|[0.0,0.0,0.851405...|\n",
      "+---------+----+------------------+-------+------------------+-------------------+--------------------------+--------------------------+------------------+-------------------------+-------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "# list of features without  'Tasa de ocupacion', 'Tasa de desempleo abierto', \n",
    "# For testing purpose\n",
    "FEATURES_LIST_FOR_TESTING = ['SubDelito', 'Hora', 'Delito', \"Victima\", \"Genero\", \"Nacionalidad\",\n",
    "                 'Poblacion de 15 anos y mas', 'Tasa neta de participacion',\n",
    "                 'Canton', 'count']\n",
    "\n",
    "def split_train_test_data(spark_df):\n",
    "    \"\"\"\n",
    "    This function splits train and test data\n",
    "    \"\"\"\n",
    "    train, test = spark_df.randomSplit([0.8, 0.2], seed=12345)\n",
    "    return train, test\n",
    "\n",
    "def select_data_for_training_models_BACK(spark_session):\n",
    "    \"\"\"\n",
    "    This function selects the data for training two models.\n",
    "    \n",
    "    Felipe la cambié por la siguiente con el fin de no modificar el codigo para las pruebas de quitar features.\n",
    "    Lo que cambia es la codificacion de las caracteristicas nada mas usando el FEATURE_LIST_FOR_TESTING.\n",
    "    \"\"\"\n",
    "    print(\"\\n- Leyendo los datos de la DB:\")\n",
    "    clean_spark_df = read_dataset_from_db(spark_session, \"datos_cruzados\")\n",
    "    \n",
    "    print(\"\\n- Condificando las características en un solo vector:\")\n",
    "    clean_vector_features_df = transform_spark_df_to_features_vector_df(clean_spark_df, remove_delito=True)\n",
    "    clean_vector_features_df.select(\"count\",\"features\").show()\n",
    "    \n",
    "    # Split train and test data\n",
    "    train_data, test_data = split_train_test_data(clean_vector_features_df)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def select_data_for_training_models(spark_session):\n",
    "    \"\"\"\n",
    "    This function selects the data for training two models\n",
    "    \"\"\"\n",
    "    print(\"\\n- Leyendo de la DB:\")\n",
    "    clean_spark_df = read_dataset_from_db(spark_session, \"datos_cruzados\")\n",
    "    \n",
    "    print(\"\\n- Condificando las características en un solo vector:\")\n",
    "    vectorAssembler = VectorAssembler(inputCols = FEATURES_LIST_FOR_TESTING[:-1], outputCol = 'features')\n",
    "    clean_vector_features_df = vectorAssembler.transform(clean_spark_df)\n",
    "    clean_vector_features_df.select(\"count\",\"features\").show()\n",
    "    \n",
    "    # Split train and test data\n",
    "    train_data, test_data = split_train_test_data(clean_vector_features_df)\n",
    "    \n",
    "    return train_data, test_data\n",
    "    #return clean_vector_features_df\n",
    "\n",
    "\n",
    "\n",
    "def training_model_using_linear_regresor(train_data):\n",
    "    \"\"\"\n",
    "    This function builds a regresion model using\n",
    "    Linear Regressor\n",
    "    \"\"\"\n",
    "    # Initialize `lr`\n",
    "    lr = LinearRegression(labelCol=\"count\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "    # Fit the data to the model\n",
    "    linearModel = lr.fit(train_data)\n",
    "    \n",
    "    \n",
    "    return linearModel\n",
    "  \n",
    "def training_model_using_generalized_linear_regression(train_data):\n",
    "    \"\"\"\n",
    "    This function builds a regresion model using\n",
    "    Generalized Linear Regressor\n",
    "    \"\"\"\n",
    "    # Initialize `lr`\n",
    "    lr = GeneralizedLinearRegression(labelCol=\"count\", family=\"Poisson\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "\n",
    "    # Fit the data to the model\n",
    "    linearModel = lr.fit(train_data)\n",
    "       \n",
    "    return linearModel\n",
    "        \n",
    "\n",
    "def training_model_decision_tree_regression(data):\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (train_data, test_data) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "    # Train a DecisionTree model.\n",
    "    dt = DecisionTreeRegressor(labelCol=\"count\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "    # Chain indexer and tree in a Pipeline\n",
    "    pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "    print(\"OJOJOJOO que tiene el train_data\")\n",
    "    print(train_data.show())\n",
    "    \n",
    "    # Train model.  This also runs the indexer.\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "def training_model_ramdom_forest_regression(train_data):\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(train_data)\n",
    "\n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestRegressor(labelCol=\"count\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "    # Chain indexer and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "    # Train model.  This also runs the indexer.\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    return model \n",
    "    \n",
    "    \n",
    "def training_model_ramdom_forest_regression(train_data):\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(train_data)\n",
    "\n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestRegressor(labelCol=\"count\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "    # Chain indexer and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "    # Train model.  This also runs the indexer.\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    return model \n",
    "     \n",
    "def training_model_gradient_boosted_tree_regression(train_data):\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(train_data)\n",
    "\n",
    "    # Train a GBT model.\n",
    "    gbt = GBTRegressor(labelCol=\"count\", featuresCol=\"indexedFeatures\", maxIter=20)\n",
    "\n",
    "    # Chain indexer and GBT in a Pipeline\n",
    "    pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "\n",
    "    # Train model.  This also runs the indexer.\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    return model \n",
    "\n",
    "def training_model_using_linear_regresor_TEST2_Completo(spark_session, train_df):\n",
    "    \"\"\"\n",
    "    This function builds a regresion model using\n",
    "    Linear Regressor\n",
    "    \"\"\"\n",
    "    \n",
    "    lr = LinearRegression(featuresCol = 'features', labelCol='count', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "    lr_model = lr.fit(train_df)\n",
    "    print(\"Coeficientes: \" + str(lr_model.coefficients))\n",
    "    print(\"Intercepción: \" + str(lr_model.intercept))    \n",
    "    \n",
    "    trainingSummary = lr_model.summary\n",
    "    print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "    print(\"r2: %f\" % trainingSummary.r2)\n",
    "    \n",
    "    return lr_model\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training Models\")\n",
    "\n",
    "#Split data in test and trining data frames.\n",
    "train_data, test_data = select_data_for_training_models(spark_session)\n",
    "\n",
    "#clean_vector_features_df = select_data_for_training_models(spark_session)\n",
    "\n",
    "#train Linear Regressor\n",
    "linearModel = training_model_using_linear_regresor(train_data)\n",
    "\n",
    "\n",
    "#train a Generalized Linear Regressor\n",
    "generalizedLinearModel = training_model_using_generalized_linear_regression(train_data)\n",
    "\n",
    "\n",
    "#train a Decision Tree Model\n",
    "decisionTreeModel = training_model_decision_tree_regression(train_data)\n",
    "\n",
    "\n",
    "#train a Ramdom Forest Model\n",
    "ramdomForestModel = training_model_ramdom_forest_regression(train_data)\n",
    "\n",
    "#train a Gradient Boosted Tree Model\n",
    "gradientBoostedTreeModel = training_model_gradient_boosted_tree_regression(train_data)\n",
    "\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HorNSbPb42PL"
   },
   "source": [
    "## c) Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dF3W47g42PM",
    "outputId": "f183dc65-4849-4c52-f342-52ae2aed887f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación del modelo de regresión lineal: \n",
      "\n",
      "Coeficientes del modelo\n",
      "[-0.3471735097836691,-0.20832720816721437,0.0,0.0,-0.10091302968626982,-0.22657034090354033,0.4537528648298835,0.0,-0.011605500792293999]\n",
      "Intercepción\n",
      "2.5539492052\n",
      "predicted\n",
      "+------------------+-----+------------------+\n",
      "|            Delito|count|        prediction|\n",
      "+------------------+-----+------------------+\n",
      "|0.8514059164505069|    2|2.6195141429245825|\n",
      "|0.8514059164505069|    2| 2.681276526961236|\n",
      "|0.8514059164505069|    1| 2.666883605289628|\n",
      "|0.8514059164505069|    2| 2.807568180703244|\n",
      "|0.8514059164505069|    1|2.8200737230832056|\n",
      "|0.8514059164505069|    1| 2.829714370012658|\n",
      "|0.8514059164505069|    1|2.4361527483756276|\n",
      "|0.8514059164505069|    4|  3.02470073748852|\n",
      "|0.8514059164505069|    1|3.1550059868766485|\n",
      "|0.8514059164505069|    1|2.6439396131767348|\n",
      "|0.8514059164505069|    1|2.5661994928108225|\n",
      "|0.8514059164505069|    4|2.6185528784899175|\n",
      "|0.8514059164505069|    4|2.6328279966511183|\n",
      "|0.8514059164505069|   18| 2.667542172100099|\n",
      "|0.8514059164505069|    8| 2.660933500230803|\n",
      "|0.8514059164505069|   10| 2.681276526961236|\n",
      "|0.8514059164505069|    3| 2.675369363889779|\n",
      "|0.8514059164505069|   12|2.7285268105101657|\n",
      "|0.8514059164505069|    6|2.7442362203879123|\n",
      "|0.8514059164505069|   34|2.8029078735873867|\n",
      "+------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "('RMSE', 4.070479822676379)\n",
      "('R2', 0.05668648286315947)\n",
      "\n",
      "Evaluación del modelo generalizado de regresión lineal: \n",
      "\n",
      "+------------------+-----+--------------------+\n",
      "|        prediction|count|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|2.5376267963562658|    2|(9,[2,6,7,8],[0.8...|\n",
      "|2.8056283403965185|    2|(9,[2,6,7,8],[0.8...|\n",
      "|2.5207328604435872|    1|(9,[2,6,7,8],[0.8...|\n",
      "| 2.986071675625597|    2|(9,[2,6,7,8],[0.8...|\n",
      "| 3.021437629670564|    1|(9,[2,6,7,8],[0.8...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) aplicado a los datos de prueba = 3.99404\n",
      "Error estándar de coeficiente: [8.061803430464247e-10, 8.211055312065292e-10, 8.500666149713054e-10, 7.695404134877175e-10, 7.037454093469593e-10, 3.601294100394077e-10, 1.0523893314427095e-09, 7.183943851022284e-10, 8.441212538348984e-10, 9.408961727258708e-09]\n",
      "T Valores: [-364561110.7646178, -238503499.97392374, 39604190.89916187, -146375395.873513, -201700878.7861174, -807404600.088349, 191071495.39681527, 887135.1020449575, -223901761.74719495, 323219777.57458645]\n",
      "P Valores: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Dispersión: 1.0\n",
      "Desviación nula: 43620.2272765\n",
      "Grado residual de libertad nulo: 15814\n",
      "Deviación: 39703.0853821\n",
      "Grado residual de libertad: 15805\n",
      "AIC: 77492.355541\n",
      "Residuos de desviación: \n",
      "+--------------------+\n",
      "|   devianceResiduals|\n",
      "+--------------------+\n",
      "| -1.0129685625757214|\n",
      "| 0.34756796410528346|\n",
      "| -0.4963973336132396|\n",
      "|  0.2977456033721866|\n",
      "| -1.1307220621119802|\n",
      "|  0.6430714223865075|\n",
      "|  -1.103707020765254|\n",
      "|-0.43777548578517544|\n",
      "| -0.5111008425097588|\n",
      "|  -1.227729634870647|\n",
      "| -1.2191224177022468|\n",
      "| -1.1780251724576227|\n",
      "|  0.9490846180051993|\n",
      "| -1.3426218467594977|\n",
      "|  -0.592154379888913|\n",
      "| -0.6502468227895164|\n",
      "| -1.4756210430795729|\n",
      "| -1.4721239215155029|\n",
      "| -0.7608498266021341|\n",
      "| 0.34160779898623295|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Evaluación del modelo regresión por árbol de decisión: \n",
      "\n",
      "+------------------+-----+--------------------+\n",
      "|        prediction|count|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|3.6085626911314983|    2|(9,[2,6,7,8],[0.8...|\n",
      "|3.6085626911314983|    2|(9,[2,6,7,8],[0.8...|\n",
      "|3.6085626911314983|    1|(9,[2,6,7,8],[0.8...|\n",
      "|3.6085626911314983|    2|(9,[2,6,7,8],[0.8...|\n",
      "|3.6085626911314983|    1|(9,[2,6,7,8],[0.8...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) de los datos de prueba = 3.58322\n",
      "DecisionTreeRegressionModel (uid=DecisionTreeRegressor_2501564a001b) of depth 5 with 63 nodes\n",
      "\n",
      "Evaluación del modelo de regresión por Ramdom Forest: \n",
      "\n",
      "+------------------+-----+--------------------+\n",
      "|        prediction|count|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|3.5669297417264203|    2|(9,[2,6,7,8],[0.8...|\n",
      "| 3.735868969758175|    2|(9,[2,6,7,8],[0.8...|\n",
      "|3.5669297417264203|    1|(9,[2,6,7,8],[0.8...|\n",
      "|3.6060677703437163|    2|(9,[2,6,7,8],[0.8...|\n",
      "| 3.871507021113538|    1|(9,[2,6,7,8],[0.8...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 3.59992\n",
      "RandomForestRegressionModel (uid=RandomForestRegressor_55b8cfae3dd4) with 20 trees\n",
      "\n",
      "Evaluación del modelo de regresión por Gradient-boosted tree : \n",
      "\n",
      "+-----------------+-----+--------------------+\n",
      "|       prediction|count|            features|\n",
      "+-----------------+-----+--------------------+\n",
      "|2.708819762756293|    2|(9,[2,6,7,8],[0.8...|\n",
      "|4.786630361479283|    2|(9,[2,6,7,8],[0.8...|\n",
      "|2.708819762756293|    1|(9,[2,6,7,8],[0.8...|\n",
      "|4.918573447074786|    2|(9,[2,6,7,8],[0.8...|\n",
      "|5.805647601827154|    1|(9,[2,6,7,8],[0.8...|\n",
      "+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 3.1916\n",
      "GBTRegressionModel (uid=GBTRegressor_79c3d5d60189) with 20 trees\n"
     ]
    }
   ],
   "source": [
    "def evaluating_linear_regresion_model(linearModel, test_data):\n",
    "    \"\"\"\n",
    "    This function evaluates the linear regresion model\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluación del modelo de regresión lineal: \\n\")\n",
    "    \n",
    "    # Coefficients for the model\n",
    "    print(\"Coeficientes del modelo\")\n",
    "    print(linearModel.coefficients)\n",
    "    \n",
    "    # Intercept for the model\n",
    "    print(\"Intercepción\")\n",
    "    print(linearModel.intercept)\n",
    "    \n",
    "        # Generate predictions\n",
    "    predicted = linearModel.transform(test_data)\n",
    "    \n",
    "    print(\"predicted\")\n",
    "    print(predicted.select('Delito', 'count', 'prediction').show())\n",
    "\n",
    "   \n",
    "    # Get the RMSE\n",
    "    print(\"RMSE\",linearModel.summary.rootMeanSquaredError)\n",
    "\n",
    "    # Get the R2\n",
    "    print(\"R2\",linearModel.summary.r2 ) \n",
    "    \n",
    "    \n",
    "def evaluating_generalized_linear_regresion_model(model, test_data):\n",
    "    \"\"\"\n",
    "    This function evaluates the linear regresion model\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluación del modelo generalizado de regresión lineal: \\n\")\n",
    "    \n",
    "    # Make predictions.\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "                labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) aplicado a los datos de prueba = %g\" % rmse)\n",
    "\n",
    "    # Summarize the model over the training set and print out some metrics\n",
    "    summary = model.summary\n",
    "    print(\"Error estándar de coeficiente: \" + str(summary.coefficientStandardErrors))\n",
    "    print(\"T Valores: \" + str(summary.tValues))\n",
    "    print(\"P Valores: \" + str(summary.pValues))\n",
    "    print(\"Dispersión: \" + str(summary.dispersion))\n",
    "    print(\"Desviación nula: \" + str(summary.nullDeviance))\n",
    "    print(\"Grado residual de libertad nulo: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "    print(\"Deviación: \" + str(summary.deviance))\n",
    "    print(\"Grado residual de libertad: \" + str(summary.residualDegreeOfFreedom))\n",
    "    print(\"AIC: \" + str(summary.aic))\n",
    "    print(\"Residuos de desviación: \")\n",
    "    summary.residuals().show()\n",
    "    \n",
    "\n",
    "def evaluating_decision_tree_regresion_model(model, test_data):\n",
    "    \"\"\"\n",
    "    This function evaluates the tree regresion model\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluación del modelo regresión por árbol de decisión: \\n\")\n",
    "\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) de los datos de prueba = %g\" % rmse)\n",
    "\n",
    "    treeModel = model.stages[1]\n",
    "    # summary only\n",
    "    print(treeModel)\n",
    "    \n",
    "\n",
    "def evaluating_ramdom_forest_regresion_model(model, test_data):\n",
    "    \"\"\"\n",
    "    This function evaluates the ramdom forest regresion model\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluación del modelo de regresión por Ramdom Forest: \\n\")\n",
    "    \n",
    "    \n",
    "    # Make predictions.\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "            labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    rfModel = model.stages[1]\n",
    "    print(rfModel)  # summary only\n",
    "\n",
    "\n",
    "def evaluating_GBT_regresion_model(model, test_data):\n",
    "    \"\"\"\n",
    "    This function evaluates the Gradient-boosted tree  regresion model\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluación del modelo de regresión por Gradient-boosted tree : \\n\")\n",
    " \n",
    "    # Make predictions.\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    gbtModel = model.stages[1]\n",
    "    print(gbtModel)  # summary only\n",
    "\n",
    "\n",
    "\n",
    "#Linear Regresion Model evaluation        \n",
    "evaluating_linear_regresion_model(linearModel, test_data)    \n",
    "\n",
    "\n",
    "#Generalized Linear Regresion Model evaluation        \n",
    "evaluating_generalized_linear_regresion_model(generalizedLinearModel, test_data)\n",
    "\n",
    "#Decision Tree Regresion Model evaluation        \n",
    "evaluating_decision_tree_regresion_model(decisionTreeModel, test_data)\n",
    "\n",
    "#Ramdom Forest Regresion Model evaluation        \n",
    "evaluating_ramdom_forest_regresion_model(ramdomForestModel, test_data)\n",
    "\n",
    "#GBT Regresion Model evaluation        \n",
    "evaluating_GBT_regresion_model(gradientBoostedTreeModel, test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sE_jXqQxHjiA"
   },
   "source": [
    "## Referencias\n",
    "\n",
    "Instituto Nacional de Estadísticas y Censos (2011). Censo 2011: Indicadores económicos, según provincia, cantón y distrito. Recuperado de http://inec.cr/documento/censo-2011-indicadores-economicos-segun-provincia-canton-y-distrito\n",
    "\n",
    "McClendon, L y Meghanathan, N (2015). Using Machine Learning Algorithms to Analyze Crime Data. Recuperado de https://www.researchgate.net/publication/275220711_Using_Machine_Learning_Algorithms_to_Analyze_Crime_Data\n",
    "\n",
    "Neale, Caleb (2019). Cross Validation: A Beginner’s Guide. Recuperado de https://towardsdatascience.com/cross-validation-a-beginners-guide-5b8ca04962cd\n",
    "\n",
    "Organismo de Investigación Judicial (2018). Estadísticas policiales. Recuperado de https://sitiooij.poder-judicial.go.cr/index.php/apertura/transparencia/estadisticas-policiales\n",
    "\n",
    "Spark (nd.). Regression. Recuperado de https://spark.apache.org/docs/latest/ml-classification-regression.html#regression\n",
    "\n",
    "Spark (nd.). ML Tuning: model selection and hyperparameter tuning. Recuperado de https://spark.apache.org/docs/latest/ml-tuning.html\n",
    "\n",
    "Spark (nd.). Evaluation Metrics - RDD-based API. Recuperado de https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html\n",
    "\n",
    "Stalidis,P., Semertzidis, T., and Daras, P. (2018). Examining Deep Learning Architectures for Crime Classification and Prediction. Recuperado de https://arxiv.org/pdf/1812.00602.pdf\n",
    "\n",
    "Suhong, K., Param, J., Parminder, K. y Pooya, T. (2018).Crime Analysis Through Machine Learning. IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qitTn2YD42PP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qs-P6HvvD4Nz",
    "27cF0odKD4N5",
    "2LMXs_iMD4N-"
   ],
   "name": "Proyecto_BI_MariaMora_FelipeMejiasV3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
